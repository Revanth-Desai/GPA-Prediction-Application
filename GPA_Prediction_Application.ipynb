{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPA Prediction Application.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Revanth-Desai/GPA-Prediction-Application/blob/main/GPA_Prediction_Application.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddzwrPkJ8DA_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('/content/OOP Lab - Data.xlsx')"
      ],
      "metadata": {
        "id": "EFsheitQ8LqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "RhPalugc8QiF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "12469251-f8f3-4aef-9b80-7cc3bd9ad7fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     S.No  Registration No              Student Name  Internal Marks  \\\n",
              "0       1        209301007           NIKHIL BHANDARI              47   \n",
              "1       2        209301011                 IVA SETHI              47   \n",
              "2       3        209301020      JASKARAN SINGH BARMI              49   \n",
              "3       4        209301037               NITYA ARORA              47   \n",
              "4       5        209301041    HARSHIT KUMAR METPALLY              49   \n",
              "..    ...              ...                       ...             ...   \n",
              "112   113        209302115         TANISHA CHAUDHARY              54   \n",
              "113   114        209302150          DEVANSHU RASTOGI              50   \n",
              "114   115        209302169            DIVYANSH MALIK              53   \n",
              "115   116        209302317  PRAJESH PRANESH YEOTIKAR              53   \n",
              "116   117        209309065           SIDDHANT KESHAV              53   \n",
              "\n",
              "     External Marks  Total Rev_Grade  \n",
              "0                34     89         A  \n",
              "1                34     89         A  \n",
              "2                37     88         A  \n",
              "3                34     88         A  \n",
              "4                36     88         A  \n",
              "..              ...    ...       ...  \n",
              "112              33     79         A  \n",
              "113              32     79         A  \n",
              "114              34     79         A  \n",
              "115              36     79         A  \n",
              "116              34     79         A  \n",
              "\n",
              "[117 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34ce5413-6890-4e98-b6b6-742b5db50407\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S.No</th>\n",
              "      <th>Registration No</th>\n",
              "      <th>Student Name</th>\n",
              "      <th>Internal Marks</th>\n",
              "      <th>External Marks</th>\n",
              "      <th>Total</th>\n",
              "      <th>Rev_Grade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>209301007</td>\n",
              "      <td>NIKHIL BHANDARI</td>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "      <td>89</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>209301011</td>\n",
              "      <td>IVA SETHI</td>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "      <td>89</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>209301020</td>\n",
              "      <td>JASKARAN SINGH BARMI</td>\n",
              "      <td>49</td>\n",
              "      <td>37</td>\n",
              "      <td>88</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>209301037</td>\n",
              "      <td>NITYA ARORA</td>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "      <td>88</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>209301041</td>\n",
              "      <td>HARSHIT KUMAR METPALLY</td>\n",
              "      <td>49</td>\n",
              "      <td>36</td>\n",
              "      <td>88</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>113</td>\n",
              "      <td>209302115</td>\n",
              "      <td>TANISHA CHAUDHARY</td>\n",
              "      <td>54</td>\n",
              "      <td>33</td>\n",
              "      <td>79</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>114</td>\n",
              "      <td>209302150</td>\n",
              "      <td>DEVANSHU RASTOGI</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>79</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>115</td>\n",
              "      <td>209302169</td>\n",
              "      <td>DIVYANSH MALIK</td>\n",
              "      <td>53</td>\n",
              "      <td>34</td>\n",
              "      <td>79</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>116</td>\n",
              "      <td>209302317</td>\n",
              "      <td>PRAJESH PRANESH YEOTIKAR</td>\n",
              "      <td>53</td>\n",
              "      <td>36</td>\n",
              "      <td>79</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>117</td>\n",
              "      <td>209309065</td>\n",
              "      <td>SIDDHANT KESHAV</td>\n",
              "      <td>53</td>\n",
              "      <td>34</td>\n",
              "      <td>79</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>117 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34ce5413-6890-4e98-b6b6-742b5db50407')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34ce5413-6890-4e98-b6b6-742b5db50407 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34ce5413-6890-4e98-b6b6-742b5db50407');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Rev_Grade'].replace(\"A+\",10,inplace = True)\n",
        "data['Rev_Grade'].replace(\"A\",9,inplace = True)\n",
        "data['Rev_Grade'].replace(\"B\",8,inplace = True)\n",
        "data['Rev_Grade'].replace(\"C\",7,inplace = True)\n",
        "data['Rev_Grade'].replace(\"D\",6,inplace = True)\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "D2YvBQ4l8Rkv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "19f4ab39-976c-4448-814c-5e84c268f7de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     S.No  Registration No              Student Name  Internal Marks  \\\n",
              "0       1        209301007           NIKHIL BHANDARI              47   \n",
              "1       2        209301011                 IVA SETHI              47   \n",
              "2       3        209301020      JASKARAN SINGH BARMI              49   \n",
              "3       4        209301037               NITYA ARORA              47   \n",
              "4       5        209301041    HARSHIT KUMAR METPALLY              49   \n",
              "..    ...              ...                       ...             ...   \n",
              "112   113        209302115         TANISHA CHAUDHARY              54   \n",
              "113   114        209302150          DEVANSHU RASTOGI              50   \n",
              "114   115        209302169            DIVYANSH MALIK              53   \n",
              "115   116        209302317  PRAJESH PRANESH YEOTIKAR              53   \n",
              "116   117        209309065           SIDDHANT KESHAV              53   \n",
              "\n",
              "     External Marks  Total  Rev_Grade  \n",
              "0                34     89          9  \n",
              "1                34     89          9  \n",
              "2                37     88          9  \n",
              "3                34     88          9  \n",
              "4                36     88          9  \n",
              "..              ...    ...        ...  \n",
              "112              33     79          9  \n",
              "113              32     79          9  \n",
              "114              34     79          9  \n",
              "115              36     79          9  \n",
              "116              34     79          9  \n",
              "\n",
              "[117 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7a21f27-7aa8-4cd9-b27d-919dc3da2c8c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S.No</th>\n",
              "      <th>Registration No</th>\n",
              "      <th>Student Name</th>\n",
              "      <th>Internal Marks</th>\n",
              "      <th>External Marks</th>\n",
              "      <th>Total</th>\n",
              "      <th>Rev_Grade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>209301007</td>\n",
              "      <td>NIKHIL BHANDARI</td>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "      <td>89</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>209301011</td>\n",
              "      <td>IVA SETHI</td>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "      <td>89</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>209301020</td>\n",
              "      <td>JASKARAN SINGH BARMI</td>\n",
              "      <td>49</td>\n",
              "      <td>37</td>\n",
              "      <td>88</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>209301037</td>\n",
              "      <td>NITYA ARORA</td>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "      <td>88</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>209301041</td>\n",
              "      <td>HARSHIT KUMAR METPALLY</td>\n",
              "      <td>49</td>\n",
              "      <td>36</td>\n",
              "      <td>88</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>113</td>\n",
              "      <td>209302115</td>\n",
              "      <td>TANISHA CHAUDHARY</td>\n",
              "      <td>54</td>\n",
              "      <td>33</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>114</td>\n",
              "      <td>209302150</td>\n",
              "      <td>DEVANSHU RASTOGI</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>115</td>\n",
              "      <td>209302169</td>\n",
              "      <td>DIVYANSH MALIK</td>\n",
              "      <td>53</td>\n",
              "      <td>34</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>116</td>\n",
              "      <td>209302317</td>\n",
              "      <td>PRAJESH PRANESH YEOTIKAR</td>\n",
              "      <td>53</td>\n",
              "      <td>36</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>117</td>\n",
              "      <td>209309065</td>\n",
              "      <td>SIDDHANT KESHAV</td>\n",
              "      <td>53</td>\n",
              "      <td>34</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>117 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7a21f27-7aa8-4cd9-b27d-919dc3da2c8c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7a21f27-7aa8-4cd9-b27d-919dc3da2c8c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7a21f27-7aa8-4cd9-b27d-919dc3da2c8c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Rev_Grade'].unique()"
      ],
      "metadata": {
        "id": "qVe9SExW8a0h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "019e0daf-3594-4d4f-887c-1dcf509cc106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9,  8,  7, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.rename(columns={\"Rev_Grade\":\"Grade_Point\"},inplace = True)"
      ],
      "metadata": {
        "id": "u7gM0qrD8frB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "eVXzeGqK8jd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "4dea800a-e5ae-48dd-def8-82e6d6106672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     S.No  Registration No              Student Name  Internal Marks  \\\n",
              "0       1        209301007           NIKHIL BHANDARI              47   \n",
              "1       2        209301011                 IVA SETHI              47   \n",
              "2       3        209301020      JASKARAN SINGH BARMI              49   \n",
              "3       4        209301037               NITYA ARORA              47   \n",
              "4       5        209301041    HARSHIT KUMAR METPALLY              49   \n",
              "..    ...              ...                       ...             ...   \n",
              "112   113        209302115         TANISHA CHAUDHARY              54   \n",
              "113   114        209302150          DEVANSHU RASTOGI              50   \n",
              "114   115        209302169            DIVYANSH MALIK              53   \n",
              "115   116        209302317  PRAJESH PRANESH YEOTIKAR              53   \n",
              "116   117        209309065           SIDDHANT KESHAV              53   \n",
              "\n",
              "     External Marks  Total  Grade_Point  \n",
              "0                34     89            9  \n",
              "1                34     89            9  \n",
              "2                37     88            9  \n",
              "3                34     88            9  \n",
              "4                36     88            9  \n",
              "..              ...    ...          ...  \n",
              "112              33     79            9  \n",
              "113              32     79            9  \n",
              "114              34     79            9  \n",
              "115              36     79            9  \n",
              "116              34     79            9  \n",
              "\n",
              "[117 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a561ec6c-69ca-41e0-ae0b-28bf4ad0efda\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S.No</th>\n",
              "      <th>Registration No</th>\n",
              "      <th>Student Name</th>\n",
              "      <th>Internal Marks</th>\n",
              "      <th>External Marks</th>\n",
              "      <th>Total</th>\n",
              "      <th>Grade_Point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>209301007</td>\n",
              "      <td>NIKHIL BHANDARI</td>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "      <td>89</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>209301011</td>\n",
              "      <td>IVA SETHI</td>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "      <td>89</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>209301020</td>\n",
              "      <td>JASKARAN SINGH BARMI</td>\n",
              "      <td>49</td>\n",
              "      <td>37</td>\n",
              "      <td>88</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>209301037</td>\n",
              "      <td>NITYA ARORA</td>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "      <td>88</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>209301041</td>\n",
              "      <td>HARSHIT KUMAR METPALLY</td>\n",
              "      <td>49</td>\n",
              "      <td>36</td>\n",
              "      <td>88</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>113</td>\n",
              "      <td>209302115</td>\n",
              "      <td>TANISHA CHAUDHARY</td>\n",
              "      <td>54</td>\n",
              "      <td>33</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>114</td>\n",
              "      <td>209302150</td>\n",
              "      <td>DEVANSHU RASTOGI</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>115</td>\n",
              "      <td>209302169</td>\n",
              "      <td>DIVYANSH MALIK</td>\n",
              "      <td>53</td>\n",
              "      <td>34</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>116</td>\n",
              "      <td>209302317</td>\n",
              "      <td>PRAJESH PRANESH YEOTIKAR</td>\n",
              "      <td>53</td>\n",
              "      <td>36</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>117</td>\n",
              "      <td>209309065</td>\n",
              "      <td>SIDDHANT KESHAV</td>\n",
              "      <td>53</td>\n",
              "      <td>34</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>117 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a561ec6c-69ca-41e0-ae0b-28bf4ad0efda')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a561ec6c-69ca-41e0-ae0b-28bf4ad0efda button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a561ec6c-69ca-41e0-ae0b-28bf4ad0efda');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp=data.copy()"
      ],
      "metadata": {
        "id": "KuydpZ-m8krM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp"
      ],
      "metadata": {
        "id": "uivpKFA48pDr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "80682cac-ced7-4bf3-b9d8-e355c521f617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     S.No  Registration No              Student Name  Internal Marks  \\\n",
              "0       1        209301007           NIKHIL BHANDARI              47   \n",
              "1       2        209301011                 IVA SETHI              47   \n",
              "2       3        209301020      JASKARAN SINGH BARMI              49   \n",
              "3       4        209301037               NITYA ARORA              47   \n",
              "4       5        209301041    HARSHIT KUMAR METPALLY              49   \n",
              "..    ...              ...                       ...             ...   \n",
              "112   113        209302115         TANISHA CHAUDHARY              54   \n",
              "113   114        209302150          DEVANSHU RASTOGI              50   \n",
              "114   115        209302169            DIVYANSH MALIK              53   \n",
              "115   116        209302317  PRAJESH PRANESH YEOTIKAR              53   \n",
              "116   117        209309065           SIDDHANT KESHAV              53   \n",
              "\n",
              "     External Marks  Total  Grade_Point  \n",
              "0                34     89            9  \n",
              "1                34     89            9  \n",
              "2                37     88            9  \n",
              "3                34     88            9  \n",
              "4                36     88            9  \n",
              "..              ...    ...          ...  \n",
              "112              33     79            9  \n",
              "113              32     79            9  \n",
              "114              34     79            9  \n",
              "115              36     79            9  \n",
              "116              34     79            9  \n",
              "\n",
              "[117 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6209f46-d2e7-4bb2-9e69-3abde793792d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S.No</th>\n",
              "      <th>Registration No</th>\n",
              "      <th>Student Name</th>\n",
              "      <th>Internal Marks</th>\n",
              "      <th>External Marks</th>\n",
              "      <th>Total</th>\n",
              "      <th>Grade_Point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>209301007</td>\n",
              "      <td>NIKHIL BHANDARI</td>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "      <td>89</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>209301011</td>\n",
              "      <td>IVA SETHI</td>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "      <td>89</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>209301020</td>\n",
              "      <td>JASKARAN SINGH BARMI</td>\n",
              "      <td>49</td>\n",
              "      <td>37</td>\n",
              "      <td>88</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>209301037</td>\n",
              "      <td>NITYA ARORA</td>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "      <td>88</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>209301041</td>\n",
              "      <td>HARSHIT KUMAR METPALLY</td>\n",
              "      <td>49</td>\n",
              "      <td>36</td>\n",
              "      <td>88</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>113</td>\n",
              "      <td>209302115</td>\n",
              "      <td>TANISHA CHAUDHARY</td>\n",
              "      <td>54</td>\n",
              "      <td>33</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>114</td>\n",
              "      <td>209302150</td>\n",
              "      <td>DEVANSHU RASTOGI</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>115</td>\n",
              "      <td>209302169</td>\n",
              "      <td>DIVYANSH MALIK</td>\n",
              "      <td>53</td>\n",
              "      <td>34</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>116</td>\n",
              "      <td>209302317</td>\n",
              "      <td>PRAJESH PRANESH YEOTIKAR</td>\n",
              "      <td>53</td>\n",
              "      <td>36</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>117</td>\n",
              "      <td>209309065</td>\n",
              "      <td>SIDDHANT KESHAV</td>\n",
              "      <td>53</td>\n",
              "      <td>34</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>117 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6209f46-d2e7-4bb2-9e69-3abde793792d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b6209f46-d2e7-4bb2-9e69-3abde793792d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b6209f46-d2e7-4bb2-9e69-3abde793792d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp.drop('Student Name',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "IXGchKhP8q4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp.drop('S.No',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "8vlOzKL583qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp"
      ],
      "metadata": {
        "id": "9cBurjoU8wCu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "4fc28b9b-d232-4dc5-d5f6-778fb89c30b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Registration No  Internal Marks  External Marks  Total  Grade_Point\n",
              "0          209301007              47              34     89            9\n",
              "1          209301011              47              34     89            9\n",
              "2          209301020              49              37     88            9\n",
              "3          209301037              47              34     88            9\n",
              "4          209301041              49              36     88            9\n",
              "..               ...             ...             ...    ...          ...\n",
              "112        209302115              54              33     79            9\n",
              "113        209302150              50              32     79            9\n",
              "114        209302169              53              34     79            9\n",
              "115        209302317              53              36     79            9\n",
              "116        209309065              53              34     79            9\n",
              "\n",
              "[117 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea3ff9f4-d7a7-484c-b2ce-d92f376f63a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Registration No</th>\n",
              "      <th>Internal Marks</th>\n",
              "      <th>External Marks</th>\n",
              "      <th>Total</th>\n",
              "      <th>Grade_Point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>209301007</td>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "      <td>89</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>209301011</td>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "      <td>89</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>209301020</td>\n",
              "      <td>49</td>\n",
              "      <td>37</td>\n",
              "      <td>88</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>209301037</td>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "      <td>88</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>209301041</td>\n",
              "      <td>49</td>\n",
              "      <td>36</td>\n",
              "      <td>88</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>209302115</td>\n",
              "      <td>54</td>\n",
              "      <td>33</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>209302150</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>209302169</td>\n",
              "      <td>53</td>\n",
              "      <td>34</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>209302317</td>\n",
              "      <td>53</td>\n",
              "      <td>36</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>209309065</td>\n",
              "      <td>53</td>\n",
              "      <td>34</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>117 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea3ff9f4-d7a7-484c-b2ce-d92f376f63a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea3ff9f4-d7a7-484c-b2ce-d92f376f63a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea3ff9f4-d7a7-484c-b2ce-d92f376f63a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp.info()"
      ],
      "metadata": {
        "id": "knYW1EFE8xNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f40f4e1-c196-4152-e590-58c740f9a5f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 117 entries, 0 to 116\n",
            "Data columns (total 5 columns):\n",
            " #   Column           Non-Null Count  Dtype\n",
            "---  ------           --------------  -----\n",
            " 0   Registration No  117 non-null    int64\n",
            " 1   Internal Marks   117 non-null    int64\n",
            " 2   External Marks   117 non-null    int64\n",
            " 3   Total            117 non-null    int64\n",
            " 4   Grade_Point      117 non-null    int64\n",
            "dtypes: int64(5)\n",
            "memory usage: 4.7 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***LINEAR REGRESSION***"
      ],
      "metadata": {
        "id": "hIrpJJeJ89Gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.DataFrame(cp,columns=['Internal Marks','External Marks'])\n",
        "y = pd.DataFrame(cp,columns=['Total','Grade_Point'])"
      ],
      "metadata": {
        "id": "FPLwF7KX9BIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "0JK9lB869kMY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "3f422a89-8b1e-48ad-acc2-f3eb283657b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Internal Marks  External Marks\n",
              "0                47              34\n",
              "1                47              34\n",
              "2                49              37\n",
              "3                47              34\n",
              "4                49              36\n",
              "..              ...             ...\n",
              "112              54              33\n",
              "113              50              32\n",
              "114              53              34\n",
              "115              53              36\n",
              "116              53              34\n",
              "\n",
              "[117 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8334bd80-e26b-4e7b-87c6-dabd0bff5061\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Internal Marks</th>\n",
              "      <th>External Marks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>49</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>49</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>54</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>53</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>53</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>53</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>117 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8334bd80-e26b-4e7b-87c6-dabd0bff5061')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8334bd80-e26b-4e7b-87c6-dabd0bff5061 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8334bd80-e26b-4e7b-87c6-dabd0bff5061');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "FAem4P3K9lTt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "41f76b27-8551-45f8-8ad4-b98c45f4aac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Total  Grade_Point\n",
              "0       89            9\n",
              "1       89            9\n",
              "2       88            9\n",
              "3       88            9\n",
              "4       88            9\n",
              "..     ...          ...\n",
              "112     79            9\n",
              "113     79            9\n",
              "114     79            9\n",
              "115     79            9\n",
              "116     79            9\n",
              "\n",
              "[117 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02ab1d95-aa22-4c76-8165-191982a81983\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>Grade_Point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>89</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>89</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>88</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>88</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>88</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>117 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02ab1d95-aa22-4c76-8165-191982a81983')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02ab1d95-aa22-4c76-8165-191982a81983 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02ab1d95-aa22-4c76-8165-191982a81983');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr=LinearRegression()"
      ],
      "metadata": {
        "id": "_Uj_Fh8g9mxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,train_size=0.7,shuffle=True,random_state=1)"
      ],
      "metadata": {
        "id": "QUnr5UEI9yUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "id": "p81-o6GW99Yy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "295b5fb0-ef54-4675-d83e-d7bd25cd545f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Internal Marks  External Marks\n",
              "32               45              33\n",
              "78               44              29\n",
              "19               47              34\n",
              "116              53              34\n",
              "27               37              27\n",
              "..              ...             ...\n",
              "9                49              34\n",
              "72               50              33\n",
              "12               45              33\n",
              "107              48              31\n",
              "37               51              37\n",
              "\n",
              "[81 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2e076c4-5a3d-4b7c-ab36-d7e08f5a2026\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Internal Marks</th>\n",
              "      <th>External Marks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>45</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>44</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>53</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>37</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>49</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>50</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>45</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>48</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>51</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>81 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2e076c4-5a3d-4b7c-ab36-d7e08f5a2026')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2e076c4-5a3d-4b7c-ab36-d7e08f5a2026 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2e076c4-5a3d-4b7c-ab36-d7e08f5a2026');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "34dLOuBg-FHX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a6b52924-d3fc-4c67-8c2b-bcb143d639bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Total  Grade_Point\n",
              "32      78            8\n",
              "78      71            8\n",
              "19      86            9\n",
              "116     79            9\n",
              "27      64            7\n",
              "..     ...          ...\n",
              "9       87            9\n",
              "72      82            9\n",
              "12      78            8\n",
              "107     79            9\n",
              "37      85            9\n",
              "\n",
              "[81 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d7a89264-3f45-4ee8-bc46-055238964f4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>Grade_Point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>78</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>71</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>86</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>64</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>87</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>82</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>78</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>85</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>81 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7a89264-3f45-4ee8-bc46-055238964f4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d7a89264-3f45-4ee8-bc46-055238964f4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d7a89264-3f45-4ee8-bc46-055238964f4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "0H3UGg6I-G0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "098e33fd-2276-4623-e879-f9241c0250ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr.score(x_test,y_test)"
      ],
      "metadata": {
        "id": "cYCyserV-LWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b5c8ba-9876-4010-8061-d425cd597ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7833900003320342"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res=np.array([[]])"
      ],
      "metadata": {
        "id": "zPDNdST--4L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = lr.predict(np.array([[53,35]]))"
      ],
      "metadata": {
        "id": "2cQF0P5L-Q5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3affe6d-59ba-4d50-debe-3d5746425b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "Am-fdaCu-aR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b4caa3-11bf-450d-d38d-67d1a6366335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[84.74674341,  9.35226373]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if(res[0][1]>9 and res[0][1]<=10):\n",
        "  print(\"Grade : \",'A+')\n",
        "elif(res[0][1]>8 and res[0][1]<=9):\n",
        "  print(\"Grade : \",'A')\n",
        "elif(res[0][1]>7 and res[0][1]<=8):\n",
        "  print(\"Grade : \",'B')\n",
        "elif(res[0][1]>6 and res[0][1]<=7):\n",
        "  print(\"Grade : \",'C')\n",
        "elif(res[0][1]>5 and res[0][1]<=6):\n",
        "  print(\"Grade : \",'D')"
      ],
      "metadata": {
        "id": "rNqC89G4-vyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6e9bb8e-2b9e-4569-dcd1-416b735f4e5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grade :  A+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "BnrLEjQj_tHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(lr,open('model1.pkl','wb'))"
      ],
      "metadata": {
        "id": "789EUAKmAxVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R7Vo4SxJVenS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor Flow Implementation"
      ],
      "metadata": {
        "id": "yur_5QvGVfmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras,lite"
      ],
      "metadata": {
        "id": "ih79twxTBGN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "q0lm4vUVRLw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(15, input_dim=2, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))"
      ],
      "metadata": {
        "id": "HltS04-VROPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])"
      ],
      "metadata": {
        "id": "iF7Nbqr5RZM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.fit(x_train, y_train, epochs=500, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kxHsZjmRehS",
        "outputId": "5e77aa28-cfd0-4bdc-a27a-c89a57c2e947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 1248.0483 - mse: 1248.0483 - mae: 35.0000 - val_loss: 1311.4958 - val_mse: 1311.4958 - val_mae: 35.9706\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1248.0398 - mse: 1248.0398 - mae: 35.0000 - val_loss: 1311.4895 - val_mse: 1311.4895 - val_mae: 35.9706\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1248.0332 - mse: 1248.0332 - mae: 35.0000 - val_loss: 1311.4795 - val_mse: 1311.4795 - val_mae: 35.9706\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1248.0299 - mse: 1248.0299 - mae: 35.0000 - val_loss: 1311.4918 - val_mse: 1311.4918 - val_mae: 35.9706\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1248.0231 - mse: 1248.0231 - mae: 35.0000 - val_loss: 1311.4595 - val_mse: 1311.4595 - val_mae: 35.9706\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1248.0171 - mse: 1248.0171 - mae: 35.0000 - val_loss: 1311.4315 - val_mse: 1311.4315 - val_mae: 35.9706\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1248.0071 - mse: 1248.0071 - mae: 35.0000 - val_loss: 1311.4347 - val_mse: 1311.4347 - val_mae: 35.9706\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1248.0015 - mse: 1248.0015 - mae: 35.0000 - val_loss: 1311.4404 - val_mse: 1311.4404 - val_mae: 35.9706\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1247.9948 - mse: 1247.9948 - mae: 35.0000 - val_loss: 1311.4266 - val_mse: 1311.4266 - val_mae: 35.9706\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1247.9883 - mse: 1247.9883 - mae: 35.0000 - val_loss: 1311.4326 - val_mse: 1311.4326 - val_mae: 35.9706\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1247.9822 - mse: 1247.9822 - mae: 35.0000 - val_loss: 1311.4398 - val_mse: 1311.4398 - val_mae: 35.9706\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1247.9756 - mse: 1247.9756 - mae: 35.0000 - val_loss: 1311.4463 - val_mse: 1311.4463 - val_mae: 35.9706\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1247.9683 - mse: 1247.9683 - mae: 35.0000 - val_loss: 1311.4407 - val_mse: 1311.4407 - val_mae: 35.9706\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.9675 - mse: 1247.9675 - mae: 35.0000 - val_loss: 1311.4589 - val_mse: 1311.4589 - val_mae: 35.9706\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.9557 - mse: 1247.9557 - mae: 35.0000 - val_loss: 1311.4475 - val_mse: 1311.4475 - val_mae: 35.9706\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.9492 - mse: 1247.9492 - mae: 35.0000 - val_loss: 1311.4337 - val_mse: 1311.4337 - val_mae: 35.9706\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.9426 - mse: 1247.9426 - mae: 35.0000 - val_loss: 1311.4275 - val_mse: 1311.4275 - val_mae: 35.9706\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1247.9395 - mse: 1247.9395 - mae: 35.0000 - val_loss: 1311.3934 - val_mse: 1311.3934 - val_mae: 35.9706\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1247.9349 - mse: 1247.9349 - mae: 35.0000 - val_loss: 1311.3590 - val_mse: 1311.3590 - val_mae: 35.9706\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.9229 - mse: 1247.9229 - mae: 35.0000 - val_loss: 1311.3566 - val_mse: 1311.3566 - val_mae: 35.9706\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1247.9178 - mse: 1247.9178 - mae: 35.0000 - val_loss: 1311.3503 - val_mse: 1311.3503 - val_mae: 35.9706\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1247.9106 - mse: 1247.9106 - mae: 35.0000 - val_loss: 1311.3567 - val_mse: 1311.3567 - val_mae: 35.9706\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.9053 - mse: 1247.9053 - mae: 35.0000 - val_loss: 1311.3684 - val_mse: 1311.3684 - val_mae: 35.9706\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.8987 - mse: 1247.8987 - mae: 35.0000 - val_loss: 1311.3594 - val_mse: 1311.3594 - val_mae: 35.9706\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1247.8918 - mse: 1247.8918 - mae: 35.0000 - val_loss: 1311.3545 - val_mse: 1311.3545 - val_mae: 35.9706\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.8865 - mse: 1247.8865 - mae: 35.0000 - val_loss: 1311.3640 - val_mse: 1311.3640 - val_mae: 35.9706\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1247.8794 - mse: 1247.8794 - mae: 35.0000 - val_loss: 1311.3584 - val_mse: 1311.3584 - val_mae: 35.9706\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1247.8734 - mse: 1247.8734 - mae: 35.0000 - val_loss: 1311.3624 - val_mse: 1311.3624 - val_mae: 35.9706\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1247.8716 - mse: 1247.8716 - mae: 35.0000 - val_loss: 1311.3361 - val_mse: 1311.3361 - val_mae: 35.9706\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.8611 - mse: 1247.8611 - mae: 35.0000 - val_loss: 1311.3314 - val_mse: 1311.3314 - val_mae: 35.9706\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.8552 - mse: 1247.8552 - mae: 35.0000 - val_loss: 1311.3319 - val_mse: 1311.3319 - val_mae: 35.9706\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1247.8489 - mse: 1247.8489 - mae: 35.0000 - val_loss: 1311.3282 - val_mse: 1311.3282 - val_mae: 35.9706\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.8448 - mse: 1247.8448 - mae: 35.0000 - val_loss: 1311.3527 - val_mse: 1311.3527 - val_mae: 35.9706\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1247.8376 - mse: 1247.8376 - mae: 35.0000 - val_loss: 1311.3655 - val_mse: 1311.3655 - val_mae: 35.9706\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1247.8314 - mse: 1247.8314 - mae: 35.0000 - val_loss: 1311.3542 - val_mse: 1311.3542 - val_mae: 35.9706\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1247.8250 - mse: 1247.8250 - mae: 35.0000 - val_loss: 1311.3447 - val_mse: 1311.3447 - val_mae: 35.9706\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1247.8198 - mse: 1247.8198 - mae: 35.0000 - val_loss: 1311.3564 - val_mse: 1311.3564 - val_mae: 35.9706\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.8125 - mse: 1247.8125 - mae: 35.0000 - val_loss: 1311.3544 - val_mse: 1311.3544 - val_mae: 35.9706\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.8066 - mse: 1247.8066 - mae: 35.0000 - val_loss: 1311.3500 - val_mse: 1311.3500 - val_mae: 35.9706\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.8003 - mse: 1247.8003 - mae: 35.0000 - val_loss: 1311.3458 - val_mse: 1311.3458 - val_mae: 35.9706\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1247.7947 - mse: 1247.7947 - mae: 35.0000 - val_loss: 1311.3345 - val_mse: 1311.3345 - val_mae: 35.9706\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.7896 - mse: 1247.7896 - mae: 35.0000 - val_loss: 1311.3347 - val_mse: 1311.3347 - val_mae: 35.9706\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.7853 - mse: 1247.7853 - mae: 35.0000 - val_loss: 1311.3118 - val_mse: 1311.3118 - val_mae: 35.9706\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.7797 - mse: 1247.7797 - mae: 35.0000 - val_loss: 1311.3271 - val_mse: 1311.3271 - val_mae: 35.9706\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.7710 - mse: 1247.7710 - mae: 35.0000 - val_loss: 1311.3193 - val_mse: 1311.3193 - val_mae: 35.9706\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1247.7676 - mse: 1247.7676 - mae: 35.0000 - val_loss: 1311.2950 - val_mse: 1311.2950 - val_mae: 35.9706\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1247.7600 - mse: 1247.7600 - mae: 35.0000 - val_loss: 1311.2842 - val_mse: 1311.2842 - val_mae: 35.9706\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1247.7634 - mse: 1247.7634 - mae: 35.0000 - val_loss: 1311.3199 - val_mse: 1311.3199 - val_mae: 35.9706\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.7488 - mse: 1247.7488 - mae: 35.0000 - val_loss: 1311.2985 - val_mse: 1311.2985 - val_mae: 35.9706\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1247.7427 - mse: 1247.7427 - mae: 35.0000 - val_loss: 1311.2798 - val_mse: 1311.2798 - val_mae: 35.9706\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.7356 - mse: 1247.7356 - mae: 35.0000 - val_loss: 1311.2830 - val_mse: 1311.2830 - val_mae: 35.9706\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1247.7350 - mse: 1247.7350 - mae: 35.0000 - val_loss: 1311.2477 - val_mse: 1311.2477 - val_mae: 35.9706\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.7234 - mse: 1247.7234 - mae: 35.0000 - val_loss: 1311.2494 - val_mse: 1311.2494 - val_mae: 35.9706\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1247.7179 - mse: 1247.7179 - mae: 35.0000 - val_loss: 1311.2461 - val_mse: 1311.2461 - val_mae: 35.9706\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.7107 - mse: 1247.7107 - mae: 35.0000 - val_loss: 1311.2491 - val_mse: 1311.2491 - val_mae: 35.9706\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1247.7052 - mse: 1247.7052 - mae: 35.0000 - val_loss: 1311.2566 - val_mse: 1311.2566 - val_mae: 35.9706\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1247.6985 - mse: 1247.6985 - mae: 35.0000 - val_loss: 1311.2600 - val_mse: 1311.2600 - val_mae: 35.9706\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.6919 - mse: 1247.6919 - mae: 35.0000 - val_loss: 1311.2522 - val_mse: 1311.2522 - val_mae: 35.9706\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.6868 - mse: 1247.6868 - mae: 35.0000 - val_loss: 1311.2560 - val_mse: 1311.2560 - val_mae: 35.9706\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.6803 - mse: 1247.6803 - mae: 35.0000 - val_loss: 1311.2411 - val_mse: 1311.2411 - val_mae: 35.9706\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1247.6750 - mse: 1247.6750 - mae: 35.0000 - val_loss: 1311.2489 - val_mse: 1311.2489 - val_mae: 35.9706\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.6682 - mse: 1247.6682 - mae: 35.0000 - val_loss: 1311.2295 - val_mse: 1311.2295 - val_mae: 35.9706\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.6614 - mse: 1247.6614 - mae: 35.0000 - val_loss: 1311.2275 - val_mse: 1311.2275 - val_mae: 35.9706\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.6573 - mse: 1247.6573 - mae: 35.0000 - val_loss: 1311.2373 - val_mse: 1311.2373 - val_mae: 35.9706\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.6530 - mse: 1247.6530 - mae: 35.0000 - val_loss: 1311.2041 - val_mse: 1311.2041 - val_mae: 35.9706\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1247.6440 - mse: 1247.6440 - mae: 35.0000 - val_loss: 1311.2108 - val_mse: 1311.2108 - val_mae: 35.9706\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1247.6366 - mse: 1247.6366 - mae: 35.0000 - val_loss: 1311.2106 - val_mse: 1311.2106 - val_mae: 35.9706\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1247.6309 - mse: 1247.6309 - mae: 35.0000 - val_loss: 1311.2100 - val_mse: 1311.2100 - val_mae: 35.9706\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.6250 - mse: 1247.6250 - mae: 35.0000 - val_loss: 1311.1892 - val_mse: 1311.1892 - val_mae: 35.9706\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.6182 - mse: 1247.6182 - mae: 35.0000 - val_loss: 1311.1772 - val_mse: 1311.1772 - val_mae: 35.9706\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1247.6119 - mse: 1247.6119 - mae: 35.0000 - val_loss: 1311.1638 - val_mse: 1311.1638 - val_mae: 35.9706\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1247.6063 - mse: 1247.6063 - mae: 35.0000 - val_loss: 1311.1592 - val_mse: 1311.1592 - val_mae: 35.9706\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1247.6000 - mse: 1247.6000 - mae: 35.0000 - val_loss: 1311.1531 - val_mse: 1311.1531 - val_mae: 35.9706\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1247.5933 - mse: 1247.5933 - mae: 35.0000 - val_loss: 1311.1473 - val_mse: 1311.1473 - val_mae: 35.9706\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.5889 - mse: 1247.5889 - mae: 35.0000 - val_loss: 1311.1302 - val_mse: 1311.1302 - val_mae: 35.9706\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.5815 - mse: 1247.5815 - mae: 35.0000 - val_loss: 1311.1456 - val_mse: 1311.1456 - val_mae: 35.9706\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1247.5752 - mse: 1247.5752 - mae: 35.0000 - val_loss: 1311.1569 - val_mse: 1311.1569 - val_mae: 35.9706\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1247.5688 - mse: 1247.5688 - mae: 35.0000 - val_loss: 1311.1399 - val_mse: 1311.1399 - val_mae: 35.9706\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.5649 - mse: 1247.5649 - mae: 35.0000 - val_loss: 1311.1162 - val_mse: 1311.1162 - val_mae: 35.9706\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1247.5549 - mse: 1247.5549 - mae: 35.0000 - val_loss: 1311.1074 - val_mse: 1311.1074 - val_mae: 35.9706\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.5630 - mse: 1247.5630 - mae: 35.0000 - val_loss: 1311.1609 - val_mse: 1311.1609 - val_mae: 35.9706\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.5454 - mse: 1247.5454 - mae: 35.0000 - val_loss: 1311.1807 - val_mse: 1311.1807 - val_mae: 35.9706\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.5415 - mse: 1247.5415 - mae: 35.0000 - val_loss: 1311.1393 - val_mse: 1311.1393 - val_mae: 35.9706\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1247.5293 - mse: 1247.5293 - mae: 35.0000 - val_loss: 1311.1515 - val_mse: 1311.1515 - val_mae: 35.9706\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1247.5208 - mse: 1247.5208 - mae: 35.0000 - val_loss: 1311.1423 - val_mse: 1311.1423 - val_mae: 35.9706\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1247.5151 - mse: 1247.5151 - mae: 35.0000 - val_loss: 1311.1268 - val_mse: 1311.1268 - val_mae: 35.9706\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1247.5073 - mse: 1247.5073 - mae: 35.0000 - val_loss: 1311.1237 - val_mse: 1311.1237 - val_mae: 35.9706\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.5012 - mse: 1247.5012 - mae: 35.0000 - val_loss: 1311.1182 - val_mse: 1311.1182 - val_mae: 35.9706\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.4937 - mse: 1247.4937 - mae: 35.0000 - val_loss: 1311.1088 - val_mse: 1311.1088 - val_mae: 35.9706\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1247.4873 - mse: 1247.4873 - mae: 35.0000 - val_loss: 1311.0873 - val_mse: 1311.0873 - val_mae: 35.9706\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1247.4824 - mse: 1247.4824 - mae: 35.0000 - val_loss: 1311.0999 - val_mse: 1311.0999 - val_mae: 35.9706\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1247.4742 - mse: 1247.4742 - mae: 35.0000 - val_loss: 1311.0712 - val_mse: 1311.0712 - val_mae: 35.9706\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1247.4709 - mse: 1247.4709 - mae: 35.0000 - val_loss: 1311.0328 - val_mse: 1311.0328 - val_mae: 35.9706\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1247.4641 - mse: 1247.4641 - mae: 35.0000 - val_loss: 1311.0005 - val_mse: 1311.0005 - val_mae: 35.9706\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.4497 - mse: 1247.4497 - mae: 35.0000 - val_loss: 1310.9974 - val_mse: 1310.9974 - val_mae: 35.9706\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1247.4429 - mse: 1247.4429 - mae: 35.0000 - val_loss: 1311.0238 - val_mse: 1311.0238 - val_mae: 35.9706\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1247.4330 - mse: 1247.4330 - mae: 35.0000 - val_loss: 1311.0066 - val_mse: 1311.0066 - val_mae: 35.9706\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.4233 - mse: 1247.4233 - mae: 35.0000 - val_loss: 1310.9940 - val_mse: 1310.9940 - val_mae: 35.9706\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1247.4125 - mse: 1247.4125 - mae: 35.0000 - val_loss: 1311.0032 - val_mse: 1311.0032 - val_mae: 35.9706\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1247.4048 - mse: 1247.4048 - mae: 35.0000 - val_loss: 1311.0160 - val_mse: 1311.0160 - val_mae: 35.9706\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1247.3937 - mse: 1247.3937 - mae: 35.0000 - val_loss: 1311.0226 - val_mse: 1311.0226 - val_mae: 35.9706\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.3832 - mse: 1247.3832 - mae: 35.0000 - val_loss: 1311.0049 - val_mse: 1311.0049 - val_mae: 35.9706\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1247.3717 - mse: 1247.3717 - mae: 35.0000 - val_loss: 1311.0078 - val_mse: 1311.0078 - val_mae: 35.9706\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1247.3623 - mse: 1247.3623 - mae: 35.0000 - val_loss: 1310.9817 - val_mse: 1310.9817 - val_mae: 35.9706\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1247.3502 - mse: 1247.3502 - mae: 35.0000 - val_loss: 1310.9924 - val_mse: 1310.9924 - val_mae: 35.9706\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1247.3353 - mse: 1247.3353 - mae: 35.0000 - val_loss: 1310.9708 - val_mse: 1310.9708 - val_mae: 35.9706\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1247.3241 - mse: 1247.3241 - mae: 35.0000 - val_loss: 1310.9763 - val_mse: 1310.9763 - val_mae: 35.9706\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1247.3086 - mse: 1247.3086 - mae: 35.0000 - val_loss: 1310.9668 - val_mse: 1310.9668 - val_mae: 35.9706\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1247.3008 - mse: 1247.3008 - mae: 35.0000 - val_loss: 1310.9109 - val_mse: 1310.9109 - val_mae: 35.9706\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.2771 - mse: 1247.2771 - mae: 35.0000 - val_loss: 1310.9020 - val_mse: 1310.9020 - val_mae: 35.9706\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.2671 - mse: 1247.2671 - mae: 35.0000 - val_loss: 1310.9132 - val_mse: 1310.9132 - val_mae: 35.9706\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.2454 - mse: 1247.2454 - mae: 35.0000 - val_loss: 1310.8752 - val_mse: 1310.8752 - val_mae: 35.9706\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1247.2295 - mse: 1247.2295 - mae: 35.0000 - val_loss: 1310.8401 - val_mse: 1310.8401 - val_mae: 35.9706\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1247.2131 - mse: 1247.2131 - mae: 35.0000 - val_loss: 1310.8328 - val_mse: 1310.8328 - val_mae: 35.9706\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.1962 - mse: 1247.1962 - mae: 35.0000 - val_loss: 1310.8208 - val_mse: 1310.8208 - val_mae: 35.9706\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1247.1807 - mse: 1247.1807 - mae: 35.0000 - val_loss: 1310.8070 - val_mse: 1310.8070 - val_mae: 35.9706\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1247.1671 - mse: 1247.1671 - mae: 35.0000 - val_loss: 1310.7897 - val_mse: 1310.7897 - val_mae: 35.9706\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1247.1512 - mse: 1247.1512 - mae: 35.0000 - val_loss: 1310.7893 - val_mse: 1310.7893 - val_mae: 35.9706\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1247.1389 - mse: 1247.1389 - mae: 35.0000 - val_loss: 1310.7722 - val_mse: 1310.7722 - val_mae: 35.9706\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1247.1239 - mse: 1247.1239 - mae: 35.0000 - val_loss: 1310.7672 - val_mse: 1310.7672 - val_mae: 35.9706\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.1108 - mse: 1247.1108 - mae: 35.0000 - val_loss: 1310.7902 - val_mse: 1310.7902 - val_mae: 35.9706\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1247.0951 - mse: 1247.0951 - mae: 35.0000 - val_loss: 1310.7928 - val_mse: 1310.7928 - val_mae: 35.9706\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1247.0820 - mse: 1247.0820 - mae: 35.0000 - val_loss: 1310.7888 - val_mse: 1310.7888 - val_mae: 35.9706\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.0698 - mse: 1247.0698 - mae: 35.0000 - val_loss: 1310.7992 - val_mse: 1310.7992 - val_mae: 35.9706\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1247.0573 - mse: 1247.0573 - mae: 35.0000 - val_loss: 1310.8123 - val_mse: 1310.8123 - val_mae: 35.9706\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1247.0442 - mse: 1247.0442 - mae: 35.0000 - val_loss: 1310.8049 - val_mse: 1310.8049 - val_mae: 35.9706\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1247.0356 - mse: 1247.0356 - mae: 35.0000 - val_loss: 1310.7864 - val_mse: 1310.7864 - val_mae: 35.9706\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1247.0195 - mse: 1247.0195 - mae: 35.0000 - val_loss: 1310.7948 - val_mse: 1310.7948 - val_mae: 35.9706\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.0085 - mse: 1247.0085 - mae: 35.0000 - val_loss: 1310.7769 - val_mse: 1310.7769 - val_mae: 35.9706\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1247.0024 - mse: 1247.0024 - mae: 35.0000 - val_loss: 1310.7440 - val_mse: 1310.7440 - val_mae: 35.9706\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.9825 - mse: 1246.9825 - mae: 35.0000 - val_loss: 1310.7671 - val_mse: 1310.7671 - val_mae: 35.9706\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1246.9694 - mse: 1246.9694 - mae: 35.0000 - val_loss: 1310.7795 - val_mse: 1310.7795 - val_mae: 35.9706\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.9562 - mse: 1246.9562 - mae: 35.0000 - val_loss: 1310.7775 - val_mse: 1310.7775 - val_mae: 35.9706\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.9460 - mse: 1246.9460 - mae: 35.0000 - val_loss: 1310.7843 - val_mse: 1310.7843 - val_mae: 35.9706\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.9387 - mse: 1246.9387 - mae: 35.0000 - val_loss: 1310.8003 - val_mse: 1310.8003 - val_mae: 35.9706\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1246.9319 - mse: 1246.9319 - mae: 35.0000 - val_loss: 1310.8046 - val_mse: 1310.8046 - val_mae: 35.9706\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.9297 - mse: 1246.9297 - mae: 35.0000 - val_loss: 1310.7845 - val_mse: 1310.7845 - val_mae: 35.9706\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.9236 - mse: 1246.9236 - mae: 35.0000 - val_loss: 1310.8057 - val_mse: 1310.8057 - val_mae: 35.9706\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.9174 - mse: 1246.9174 - mae: 35.0000 - val_loss: 1310.8014 - val_mse: 1310.8014 - val_mae: 35.9706\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.9137 - mse: 1246.9137 - mae: 35.0000 - val_loss: 1310.8131 - val_mse: 1310.8131 - val_mae: 35.9706\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.9099 - mse: 1246.9099 - mae: 35.0000 - val_loss: 1310.7930 - val_mse: 1310.7930 - val_mae: 35.9706\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.9036 - mse: 1246.9036 - mae: 35.0000 - val_loss: 1310.7847 - val_mse: 1310.7847 - val_mae: 35.9706\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.8994 - mse: 1246.8994 - mae: 35.0000 - val_loss: 1310.7773 - val_mse: 1310.7773 - val_mae: 35.9706\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1246.8945 - mse: 1246.8945 - mae: 35.0000 - val_loss: 1310.7698 - val_mse: 1310.7698 - val_mae: 35.9706\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.8916 - mse: 1246.8916 - mae: 35.0000 - val_loss: 1310.7577 - val_mse: 1310.7577 - val_mae: 35.9706\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1246.8909 - mse: 1246.8909 - mae: 35.0000 - val_loss: 1310.7360 - val_mse: 1310.7360 - val_mae: 35.9706\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.8860 - mse: 1246.8860 - mae: 35.0000 - val_loss: 1310.7667 - val_mse: 1310.7667 - val_mae: 35.9706\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.8833 - mse: 1246.8833 - mae: 35.0000 - val_loss: 1310.7417 - val_mse: 1310.7417 - val_mae: 35.9706\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1246.8750 - mse: 1246.8750 - mae: 35.0000 - val_loss: 1310.7439 - val_mse: 1310.7439 - val_mae: 35.9706\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.8716 - mse: 1246.8716 - mae: 35.0000 - val_loss: 1310.7607 - val_mse: 1310.7607 - val_mae: 35.9706\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.8672 - mse: 1246.8672 - mae: 35.0000 - val_loss: 1310.7549 - val_mse: 1310.7549 - val_mae: 35.9706\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.8632 - mse: 1246.8632 - mae: 35.0000 - val_loss: 1310.7584 - val_mse: 1310.7584 - val_mae: 35.9706\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1246.8597 - mse: 1246.8597 - mae: 35.0000 - val_loss: 1310.7588 - val_mse: 1310.7588 - val_mae: 35.9706\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1246.8558 - mse: 1246.8558 - mae: 35.0000 - val_loss: 1310.7505 - val_mse: 1310.7505 - val_mae: 35.9706\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.8527 - mse: 1246.8527 - mae: 35.0000 - val_loss: 1310.7623 - val_mse: 1310.7623 - val_mae: 35.9706\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.8491 - mse: 1246.8491 - mae: 35.0000 - val_loss: 1310.7455 - val_mse: 1310.7455 - val_mae: 35.9706\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.8447 - mse: 1246.8447 - mae: 35.0000 - val_loss: 1310.7349 - val_mse: 1310.7349 - val_mae: 35.9706\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.8413 - mse: 1246.8413 - mae: 35.0000 - val_loss: 1310.7468 - val_mse: 1310.7468 - val_mae: 35.9706\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.8389 - mse: 1246.8389 - mae: 35.0000 - val_loss: 1310.7621 - val_mse: 1310.7621 - val_mae: 35.9706\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1246.8328 - mse: 1246.8328 - mae: 35.0000 - val_loss: 1310.7543 - val_mse: 1310.7543 - val_mae: 35.9706\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1246.8308 - mse: 1246.8308 - mae: 35.0000 - val_loss: 1310.7627 - val_mse: 1310.7627 - val_mae: 35.9706\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1246.8267 - mse: 1246.8267 - mae: 35.0000 - val_loss: 1310.7354 - val_mse: 1310.7354 - val_mae: 35.9706\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.8209 - mse: 1246.8209 - mae: 35.0000 - val_loss: 1310.7246 - val_mse: 1310.7246 - val_mae: 35.9706\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.8177 - mse: 1246.8177 - mae: 35.0000 - val_loss: 1310.7075 - val_mse: 1310.7075 - val_mae: 35.9706\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.8173 - mse: 1246.8173 - mae: 35.0000 - val_loss: 1310.6763 - val_mse: 1310.6763 - val_mae: 35.9706\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1246.8101 - mse: 1246.8101 - mae: 35.0000 - val_loss: 1310.6727 - val_mse: 1310.6727 - val_mae: 35.9706\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.8079 - mse: 1246.8079 - mae: 35.0000 - val_loss: 1310.6564 - val_mse: 1310.6564 - val_mae: 35.9706\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1246.8053 - mse: 1246.8053 - mae: 35.0000 - val_loss: 1310.6826 - val_mse: 1310.6826 - val_mae: 35.9706\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.7986 - mse: 1246.7986 - mae: 35.0000 - val_loss: 1310.6865 - val_mse: 1310.6865 - val_mae: 35.9706\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.7961 - mse: 1246.7961 - mae: 35.0000 - val_loss: 1310.6993 - val_mse: 1310.6993 - val_mae: 35.9706\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.7925 - mse: 1246.7925 - mae: 35.0000 - val_loss: 1310.7114 - val_mse: 1310.7114 - val_mae: 35.9706\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.7917 - mse: 1246.7917 - mae: 35.0000 - val_loss: 1310.7295 - val_mse: 1310.7295 - val_mae: 35.9706\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1246.7859 - mse: 1246.7859 - mae: 35.0000 - val_loss: 1310.7356 - val_mse: 1310.7356 - val_mae: 35.9706\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1246.7821 - mse: 1246.7821 - mae: 35.0000 - val_loss: 1310.7030 - val_mse: 1310.7030 - val_mae: 35.9706\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.7771 - mse: 1246.7771 - mae: 35.0000 - val_loss: 1310.6782 - val_mse: 1310.6782 - val_mae: 35.9706\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.7734 - mse: 1246.7734 - mae: 35.0000 - val_loss: 1310.6808 - val_mse: 1310.6808 - val_mae: 35.9706\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.7688 - mse: 1246.7688 - mae: 35.0000 - val_loss: 1310.6650 - val_mse: 1310.6650 - val_mae: 35.9706\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.7756 - mse: 1246.7756 - mae: 35.0000 - val_loss: 1310.6965 - val_mse: 1310.6965 - val_mae: 35.9706\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1246.7639 - mse: 1246.7639 - mae: 35.0000 - val_loss: 1310.7024 - val_mse: 1310.7024 - val_mae: 35.9706\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.7579 - mse: 1246.7579 - mae: 35.0000 - val_loss: 1310.6772 - val_mse: 1310.6772 - val_mae: 35.9706\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1246.7560 - mse: 1246.7560 - mae: 35.0000 - val_loss: 1310.6464 - val_mse: 1310.6464 - val_mae: 35.9706\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.7507 - mse: 1246.7507 - mae: 35.0000 - val_loss: 1310.6292 - val_mse: 1310.6292 - val_mae: 35.9706\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.7493 - mse: 1246.7493 - mae: 35.0000 - val_loss: 1310.6041 - val_mse: 1310.6041 - val_mae: 35.9706\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.7472 - mse: 1246.7472 - mae: 35.0000 - val_loss: 1310.5809 - val_mse: 1310.5809 - val_mae: 35.9706\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.7400 - mse: 1246.7400 - mae: 35.0000 - val_loss: 1310.5883 - val_mse: 1310.5883 - val_mae: 35.9706\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1246.7367 - mse: 1246.7367 - mae: 35.0000 - val_loss: 1310.6075 - val_mse: 1310.6075 - val_mae: 35.9706\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1246.7389 - mse: 1246.7389 - mae: 35.0000 - val_loss: 1310.6450 - val_mse: 1310.6450 - val_mae: 35.9706\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.7317 - mse: 1246.7317 - mae: 35.0000 - val_loss: 1310.6666 - val_mse: 1310.6666 - val_mae: 35.9706\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.7336 - mse: 1246.7336 - mae: 35.0000 - val_loss: 1310.6244 - val_mse: 1310.6244 - val_mae: 35.9706\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.7217 - mse: 1246.7217 - mae: 35.0000 - val_loss: 1310.6191 - val_mse: 1310.6191 - val_mae: 35.9706\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1246.7211 - mse: 1246.7211 - mae: 35.0000 - val_loss: 1310.6440 - val_mse: 1310.6440 - val_mae: 35.9706\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.7180 - mse: 1246.7180 - mae: 35.0000 - val_loss: 1310.6647 - val_mse: 1310.6647 - val_mae: 35.9706\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1246.7119 - mse: 1246.7119 - mae: 35.0000 - val_loss: 1310.6704 - val_mse: 1310.6704 - val_mae: 35.9706\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.7070 - mse: 1246.7070 - mae: 35.0000 - val_loss: 1310.6611 - val_mse: 1310.6611 - val_mae: 35.9706\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1246.7037 - mse: 1246.7037 - mae: 35.0000 - val_loss: 1310.6464 - val_mse: 1310.6464 - val_mae: 35.9706\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1246.7000 - mse: 1246.7000 - mae: 35.0000 - val_loss: 1310.6349 - val_mse: 1310.6349 - val_mae: 35.9706\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.6995 - mse: 1246.6995 - mae: 35.0000 - val_loss: 1310.6465 - val_mse: 1310.6465 - val_mae: 35.9706\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.6930 - mse: 1246.6930 - mae: 35.0000 - val_loss: 1310.6334 - val_mse: 1310.6334 - val_mae: 35.9706\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.6892 - mse: 1246.6892 - mae: 35.0000 - val_loss: 1310.6184 - val_mse: 1310.6184 - val_mae: 35.9706\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1246.6860 - mse: 1246.6860 - mae: 35.0000 - val_loss: 1310.5994 - val_mse: 1310.5994 - val_mae: 35.9706\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.6824 - mse: 1246.6824 - mae: 35.0000 - val_loss: 1310.5852 - val_mse: 1310.5852 - val_mae: 35.9706\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1246.6816 - mse: 1246.6816 - mae: 35.0000 - val_loss: 1310.6002 - val_mse: 1310.6002 - val_mae: 35.9706\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.6821 - mse: 1246.6821 - mae: 35.0000 - val_loss: 1310.5581 - val_mse: 1310.5581 - val_mae: 35.9706\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.6749 - mse: 1246.6749 - mae: 35.0000 - val_loss: 1310.5792 - val_mse: 1310.5792 - val_mae: 35.9706\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.6682 - mse: 1246.6682 - mae: 35.0000 - val_loss: 1310.5710 - val_mse: 1310.5710 - val_mae: 35.9706\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1246.6650 - mse: 1246.6650 - mae: 35.0000 - val_loss: 1310.5629 - val_mse: 1310.5629 - val_mae: 35.9706\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.6633 - mse: 1246.6633 - mae: 35.0000 - val_loss: 1310.5453 - val_mse: 1310.5453 - val_mae: 35.9706\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.6584 - mse: 1246.6584 - mae: 35.0000 - val_loss: 1310.5386 - val_mse: 1310.5386 - val_mae: 35.9706\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.6553 - mse: 1246.6553 - mae: 35.0000 - val_loss: 1310.5352 - val_mse: 1310.5352 - val_mae: 35.9706\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.6600 - mse: 1246.6600 - mae: 35.0000 - val_loss: 1310.5815 - val_mse: 1310.5815 - val_mae: 35.9706\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.6489 - mse: 1246.6489 - mae: 35.0000 - val_loss: 1310.6002 - val_mse: 1310.6002 - val_mae: 35.9706\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.6504 - mse: 1246.6504 - mae: 35.0000 - val_loss: 1310.5657 - val_mse: 1310.5657 - val_mae: 35.9706\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.6450 - mse: 1246.6450 - mae: 35.0000 - val_loss: 1310.5414 - val_mse: 1310.5414 - val_mae: 35.9706\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.6379 - mse: 1246.6379 - mae: 35.0000 - val_loss: 1310.5582 - val_mse: 1310.5582 - val_mae: 35.9706\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.6333 - mse: 1246.6333 - mae: 35.0000 - val_loss: 1310.5612 - val_mse: 1310.5612 - val_mae: 35.9706\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.6312 - mse: 1246.6312 - mae: 35.0000 - val_loss: 1310.5796 - val_mse: 1310.5796 - val_mae: 35.9706\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.6274 - mse: 1246.6274 - mae: 35.0000 - val_loss: 1310.5875 - val_mse: 1310.5875 - val_mae: 35.9706\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.6248 - mse: 1246.6248 - mae: 35.0000 - val_loss: 1310.6006 - val_mse: 1310.6006 - val_mae: 35.9706\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1246.6204 - mse: 1246.6204 - mae: 35.0000 - val_loss: 1310.5895 - val_mse: 1310.5895 - val_mae: 35.9706\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.6230 - mse: 1246.6230 - mae: 35.0000 - val_loss: 1310.6145 - val_mse: 1310.6145 - val_mae: 35.9706\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1246.6145 - mse: 1246.6145 - mae: 35.0000 - val_loss: 1310.6132 - val_mse: 1310.6132 - val_mae: 35.9706\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.6111 - mse: 1246.6111 - mae: 35.0000 - val_loss: 1310.5859 - val_mse: 1310.5859 - val_mae: 35.9706\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.6086 - mse: 1246.6086 - mae: 35.0000 - val_loss: 1310.5529 - val_mse: 1310.5529 - val_mae: 35.9706\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.6072 - mse: 1246.6072 - mae: 35.0000 - val_loss: 1310.5681 - val_mse: 1310.5681 - val_mae: 35.9706\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.6000 - mse: 1246.6000 - mae: 35.0000 - val_loss: 1310.5492 - val_mse: 1310.5492 - val_mae: 35.9706\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.5967 - mse: 1246.5967 - mae: 35.0000 - val_loss: 1310.5333 - val_mse: 1310.5333 - val_mae: 35.9706\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1246.5940 - mse: 1246.5940 - mae: 35.0000 - val_loss: 1310.5347 - val_mse: 1310.5347 - val_mae: 35.9706\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.5908 - mse: 1246.5908 - mae: 35.0000 - val_loss: 1310.5126 - val_mse: 1310.5126 - val_mae: 35.9706\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.5864 - mse: 1246.5864 - mae: 35.0000 - val_loss: 1310.5099 - val_mse: 1310.5099 - val_mae: 35.9706\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.5863 - mse: 1246.5863 - mae: 35.0000 - val_loss: 1310.4823 - val_mse: 1310.4823 - val_mae: 35.9706\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.5811 - mse: 1246.5811 - mae: 35.0000 - val_loss: 1310.4691 - val_mse: 1310.4691 - val_mae: 35.9706\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.5769 - mse: 1246.5769 - mae: 35.0000 - val_loss: 1310.4692 - val_mse: 1310.4692 - val_mae: 35.9706\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.5739 - mse: 1246.5739 - mae: 35.0000 - val_loss: 1310.4835 - val_mse: 1310.4835 - val_mae: 35.9706\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.5703 - mse: 1246.5703 - mae: 35.0000 - val_loss: 1310.4945 - val_mse: 1310.4945 - val_mae: 35.9706\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.5669 - mse: 1246.5669 - mae: 35.0000 - val_loss: 1310.4945 - val_mse: 1310.4945 - val_mae: 35.9706\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.5642 - mse: 1246.5642 - mae: 35.0000 - val_loss: 1310.5135 - val_mse: 1310.5135 - val_mae: 35.9706\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.5619 - mse: 1246.5619 - mae: 35.0000 - val_loss: 1310.4976 - val_mse: 1310.4976 - val_mae: 35.9706\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.5566 - mse: 1246.5566 - mae: 35.0000 - val_loss: 1310.5010 - val_mse: 1310.5010 - val_mae: 35.9706\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.5538 - mse: 1246.5538 - mae: 35.0000 - val_loss: 1310.5081 - val_mse: 1310.5081 - val_mae: 35.9706\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.5505 - mse: 1246.5505 - mae: 35.0000 - val_loss: 1310.5143 - val_mse: 1310.5143 - val_mae: 35.9706\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.5486 - mse: 1246.5486 - mae: 35.0000 - val_loss: 1310.5280 - val_mse: 1310.5280 - val_mae: 35.9706\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1246.5439 - mse: 1246.5439 - mae: 35.0000 - val_loss: 1310.5233 - val_mse: 1310.5233 - val_mae: 35.9706\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.5444 - mse: 1246.5444 - mae: 35.0000 - val_loss: 1310.4924 - val_mse: 1310.4924 - val_mae: 35.9706\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1246.5386 - mse: 1246.5386 - mae: 35.0000 - val_loss: 1310.5059 - val_mse: 1310.5059 - val_mae: 35.9706\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.5341 - mse: 1246.5341 - mae: 35.0000 - val_loss: 1310.5012 - val_mse: 1310.5012 - val_mae: 35.9706\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.5312 - mse: 1246.5312 - mae: 35.0000 - val_loss: 1310.5027 - val_mse: 1310.5027 - val_mae: 35.9706\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.5278 - mse: 1246.5278 - mae: 35.0000 - val_loss: 1310.4961 - val_mse: 1310.4961 - val_mae: 35.9706\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1246.5249 - mse: 1246.5249 - mae: 35.0000 - val_loss: 1310.4869 - val_mse: 1310.4869 - val_mae: 35.9706\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.5215 - mse: 1246.5215 - mae: 35.0000 - val_loss: 1310.4823 - val_mse: 1310.4823 - val_mae: 35.9706\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.5184 - mse: 1246.5184 - mae: 35.0000 - val_loss: 1310.4790 - val_mse: 1310.4790 - val_mae: 35.9706\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.5208 - mse: 1246.5208 - mae: 35.0000 - val_loss: 1310.4442 - val_mse: 1310.4442 - val_mae: 35.9706\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.5123 - mse: 1246.5123 - mae: 35.0000 - val_loss: 1310.4415 - val_mse: 1310.4415 - val_mae: 35.9706\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1246.5087 - mse: 1246.5087 - mae: 35.0000 - val_loss: 1310.4464 - val_mse: 1310.4464 - val_mae: 35.9706\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.5093 - mse: 1246.5093 - mae: 35.0000 - val_loss: 1310.4736 - val_mse: 1310.4736 - val_mae: 35.9706\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.5027 - mse: 1246.5027 - mae: 35.0000 - val_loss: 1310.4734 - val_mse: 1310.4734 - val_mae: 35.9706\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.4995 - mse: 1246.4995 - mae: 35.0000 - val_loss: 1310.4674 - val_mse: 1310.4674 - val_mae: 35.9706\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.4965 - mse: 1246.4965 - mae: 35.0000 - val_loss: 1310.4724 - val_mse: 1310.4724 - val_mae: 35.9706\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.4969 - mse: 1246.4969 - mae: 35.0000 - val_loss: 1310.4430 - val_mse: 1310.4430 - val_mae: 35.9706\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.4897 - mse: 1246.4897 - mae: 35.0000 - val_loss: 1310.4407 - val_mse: 1310.4407 - val_mae: 35.9706\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.4882 - mse: 1246.4882 - mae: 35.0000 - val_loss: 1310.4280 - val_mse: 1310.4280 - val_mae: 35.9706\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.4860 - mse: 1246.4860 - mae: 35.0000 - val_loss: 1310.4509 - val_mse: 1310.4509 - val_mae: 35.9706\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.4812 - mse: 1246.4812 - mae: 35.0000 - val_loss: 1310.4408 - val_mse: 1310.4408 - val_mae: 35.9706\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.4855 - mse: 1246.4855 - mae: 35.0000 - val_loss: 1310.4055 - val_mse: 1310.4055 - val_mae: 35.9706\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.4747 - mse: 1246.4747 - mae: 35.0000 - val_loss: 1310.4148 - val_mse: 1310.4148 - val_mae: 35.9706\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1246.4723 - mse: 1246.4723 - mae: 35.0000 - val_loss: 1310.4340 - val_mse: 1310.4340 - val_mae: 35.9706\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.4685 - mse: 1246.4685 - mae: 35.0000 - val_loss: 1310.4331 - val_mse: 1310.4331 - val_mae: 35.9706\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.4656 - mse: 1246.4656 - mae: 35.0000 - val_loss: 1310.4429 - val_mse: 1310.4429 - val_mae: 35.9706\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.4626 - mse: 1246.4626 - mae: 35.0000 - val_loss: 1310.4387 - val_mse: 1310.4387 - val_mae: 35.9706\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.4612 - mse: 1246.4612 - mae: 35.0000 - val_loss: 1310.4581 - val_mse: 1310.4581 - val_mae: 35.9706\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.4564 - mse: 1246.4564 - mae: 35.0000 - val_loss: 1310.4545 - val_mse: 1310.4545 - val_mae: 35.9706\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.4602 - mse: 1246.4602 - mae: 35.0000 - val_loss: 1310.4155 - val_mse: 1310.4155 - val_mae: 35.9706\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.4509 - mse: 1246.4509 - mae: 35.0000 - val_loss: 1310.4277 - val_mse: 1310.4277 - val_mae: 35.9706\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.4473 - mse: 1246.4473 - mae: 35.0000 - val_loss: 1310.4325 - val_mse: 1310.4325 - val_mae: 35.9706\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.4446 - mse: 1246.4446 - mae: 35.0000 - val_loss: 1310.4208 - val_mse: 1310.4208 - val_mae: 35.9706\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.4413 - mse: 1246.4413 - mae: 35.0000 - val_loss: 1310.4154 - val_mse: 1310.4154 - val_mae: 35.9706\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.4382 - mse: 1246.4382 - mae: 35.0000 - val_loss: 1310.4205 - val_mse: 1310.4205 - val_mae: 35.9706\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1246.4403 - mse: 1246.4403 - mae: 35.0000 - val_loss: 1310.3878 - val_mse: 1310.3878 - val_mae: 35.9706\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.4326 - mse: 1246.4326 - mae: 35.0000 - val_loss: 1310.3807 - val_mse: 1310.3807 - val_mae: 35.9706\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.4296 - mse: 1246.4296 - mae: 35.0000 - val_loss: 1310.3760 - val_mse: 1310.3760 - val_mae: 35.9706\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.4327 - mse: 1246.4327 - mae: 35.0000 - val_loss: 1310.4133 - val_mse: 1310.4133 - val_mae: 35.9706\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.4238 - mse: 1246.4238 - mae: 35.0000 - val_loss: 1310.4182 - val_mse: 1310.4182 - val_mae: 35.9706\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.4209 - mse: 1246.4209 - mae: 35.0000 - val_loss: 1310.4176 - val_mse: 1310.4176 - val_mae: 35.9706\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.4176 - mse: 1246.4176 - mae: 35.0000 - val_loss: 1310.4133 - val_mse: 1310.4133 - val_mae: 35.9706\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.4146 - mse: 1246.4146 - mae: 35.0000 - val_loss: 1310.4076 - val_mse: 1310.4076 - val_mae: 35.9706\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.4185 - mse: 1246.4185 - mae: 35.0000 - val_loss: 1310.3666 - val_mse: 1310.3666 - val_mae: 35.9706\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.4136 - mse: 1246.4136 - mae: 35.0000 - val_loss: 1310.3374 - val_mse: 1310.3374 - val_mae: 35.9706\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.4067 - mse: 1246.4067 - mae: 35.0000 - val_loss: 1310.3555 - val_mse: 1310.3555 - val_mae: 35.9706\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.4042 - mse: 1246.4042 - mae: 35.0000 - val_loss: 1310.3748 - val_mse: 1310.3748 - val_mae: 35.9706\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.4080 - mse: 1246.4080 - mae: 35.0000 - val_loss: 1310.3387 - val_mse: 1310.3387 - val_mae: 35.9706\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.3970 - mse: 1246.3970 - mae: 35.0000 - val_loss: 1310.3518 - val_mse: 1310.3518 - val_mae: 35.9706\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.3940 - mse: 1246.3940 - mae: 35.0000 - val_loss: 1310.3566 - val_mse: 1310.3566 - val_mae: 35.9706\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.3955 - mse: 1246.3955 - mae: 35.0000 - val_loss: 1310.3907 - val_mse: 1310.3907 - val_mae: 35.9706\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.3904 - mse: 1246.3904 - mae: 35.0000 - val_loss: 1310.4086 - val_mse: 1310.4086 - val_mae: 35.9706\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.3857 - mse: 1246.3857 - mae: 35.0000 - val_loss: 1310.4038 - val_mse: 1310.4038 - val_mae: 35.9706\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.3833 - mse: 1246.3833 - mae: 35.0000 - val_loss: 1310.4033 - val_mse: 1310.4033 - val_mae: 35.9706\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.3799 - mse: 1246.3799 - mae: 35.0000 - val_loss: 1310.3977 - val_mse: 1310.3977 - val_mae: 35.9706\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.3790 - mse: 1246.3790 - mae: 35.0000 - val_loss: 1310.4055 - val_mse: 1310.4055 - val_mae: 35.9706\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.3744 - mse: 1246.3744 - mae: 35.0000 - val_loss: 1310.3888 - val_mse: 1310.3888 - val_mae: 35.9706\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.3772 - mse: 1246.3772 - mae: 35.0000 - val_loss: 1310.4061 - val_mse: 1310.4061 - val_mae: 35.9706\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.3694 - mse: 1246.3694 - mae: 35.0000 - val_loss: 1310.3977 - val_mse: 1310.3977 - val_mae: 35.9706\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1246.3689 - mse: 1246.3689 - mae: 35.0000 - val_loss: 1310.3983 - val_mse: 1310.3983 - val_mae: 35.9706\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1246.3628 - mse: 1246.3628 - mae: 35.0000 - val_loss: 1310.3728 - val_mse: 1310.3728 - val_mae: 35.9706\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.3601 - mse: 1246.3601 - mae: 35.0000 - val_loss: 1310.3470 - val_mse: 1310.3470 - val_mae: 35.9706\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.3593 - mse: 1246.3593 - mae: 35.0000 - val_loss: 1310.3080 - val_mse: 1310.3080 - val_mae: 35.9706\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.3552 - mse: 1246.3552 - mae: 35.0000 - val_loss: 1310.2839 - val_mse: 1310.2839 - val_mae: 35.9706\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.3525 - mse: 1246.3525 - mae: 35.0000 - val_loss: 1310.2683 - val_mse: 1310.2683 - val_mae: 35.9706\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.3496 - mse: 1246.3496 - mae: 35.0000 - val_loss: 1310.2725 - val_mse: 1310.2725 - val_mae: 35.9706\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.3467 - mse: 1246.3467 - mae: 35.0000 - val_loss: 1310.2712 - val_mse: 1310.2712 - val_mae: 35.9706\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.3448 - mse: 1246.3448 - mae: 35.0000 - val_loss: 1310.2601 - val_mse: 1310.2601 - val_mae: 35.9706\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.3436 - mse: 1246.3436 - mae: 35.0000 - val_loss: 1310.2860 - val_mse: 1310.2860 - val_mae: 35.9706\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.3380 - mse: 1246.3380 - mae: 35.0000 - val_loss: 1310.2867 - val_mse: 1310.2867 - val_mae: 35.9706\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.3358 - mse: 1246.3358 - mae: 35.0000 - val_loss: 1310.3018 - val_mse: 1310.3018 - val_mae: 35.9706\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.3337 - mse: 1246.3337 - mae: 35.0000 - val_loss: 1310.2930 - val_mse: 1310.2930 - val_mae: 35.9706\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.3307 - mse: 1246.3307 - mae: 35.0000 - val_loss: 1310.3107 - val_mse: 1310.3107 - val_mae: 35.9706\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.3359 - mse: 1246.3359 - mae: 35.0000 - val_loss: 1310.3530 - val_mse: 1310.3530 - val_mae: 35.9706\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.3248 - mse: 1246.3248 - mae: 35.0000 - val_loss: 1310.3391 - val_mse: 1310.3391 - val_mae: 35.9706\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.3232 - mse: 1246.3232 - mae: 35.0000 - val_loss: 1310.3474 - val_mse: 1310.3474 - val_mae: 35.9706\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.3229 - mse: 1246.3229 - mae: 35.0000 - val_loss: 1310.3118 - val_mse: 1310.3118 - val_mae: 35.9706\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1246.3171 - mse: 1246.3171 - mae: 35.0000 - val_loss: 1310.2961 - val_mse: 1310.2961 - val_mae: 35.9706\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.3140 - mse: 1246.3140 - mae: 35.0000 - val_loss: 1310.3004 - val_mse: 1310.3004 - val_mae: 35.9706\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.3157 - mse: 1246.3157 - mae: 35.0000 - val_loss: 1310.3257 - val_mse: 1310.3257 - val_mae: 35.9706\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.3120 - mse: 1246.3120 - mae: 35.0000 - val_loss: 1310.2919 - val_mse: 1310.2919 - val_mae: 35.9706\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.3059 - mse: 1246.3059 - mae: 35.0000 - val_loss: 1310.2963 - val_mse: 1310.2963 - val_mae: 35.9706\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.3031 - mse: 1246.3031 - mae: 35.0000 - val_loss: 1310.2900 - val_mse: 1310.2900 - val_mae: 35.9706\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1246.3015 - mse: 1246.3015 - mae: 35.0000 - val_loss: 1310.2709 - val_mse: 1310.2709 - val_mae: 35.9706\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.2979 - mse: 1246.2979 - mae: 35.0000 - val_loss: 1310.2708 - val_mse: 1310.2708 - val_mae: 35.9706\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1246.2974 - mse: 1246.2974 - mae: 35.0000 - val_loss: 1310.2507 - val_mse: 1310.2507 - val_mae: 35.9706\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.2927 - mse: 1246.2927 - mae: 35.0000 - val_loss: 1310.2467 - val_mse: 1310.2467 - val_mae: 35.9706\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.2905 - mse: 1246.2905 - mae: 35.0000 - val_loss: 1310.2598 - val_mse: 1310.2598 - val_mae: 35.9706\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.2894 - mse: 1246.2894 - mae: 35.0000 - val_loss: 1310.2439 - val_mse: 1310.2439 - val_mae: 35.9706\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.2910 - mse: 1246.2910 - mae: 35.0000 - val_loss: 1310.2850 - val_mse: 1310.2850 - val_mae: 35.9706\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.2832 - mse: 1246.2832 - mae: 35.0000 - val_loss: 1310.2732 - val_mse: 1310.2732 - val_mae: 35.9706\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1246.2834 - mse: 1246.2834 - mae: 35.0000 - val_loss: 1310.3004 - val_mse: 1310.3004 - val_mae: 35.9706\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1246.2830 - mse: 1246.2830 - mae: 35.0000 - val_loss: 1310.3281 - val_mse: 1310.3281 - val_mae: 35.9706\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.2793 - mse: 1246.2793 - mae: 35.0000 - val_loss: 1310.3429 - val_mse: 1310.3429 - val_mae: 35.9706\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.2781 - mse: 1246.2781 - mae: 35.0000 - val_loss: 1310.2893 - val_mse: 1310.2893 - val_mae: 35.9706\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.2729 - mse: 1246.2729 - mae: 35.0000 - val_loss: 1310.3003 - val_mse: 1310.3003 - val_mae: 35.9706\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.2671 - mse: 1246.2671 - mae: 35.0000 - val_loss: 1310.2760 - val_mse: 1310.2760 - val_mae: 35.9706\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.2655 - mse: 1246.2655 - mae: 35.0000 - val_loss: 1310.2451 - val_mse: 1310.2451 - val_mae: 35.9706\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.2642 - mse: 1246.2642 - mae: 35.0000 - val_loss: 1310.2565 - val_mse: 1310.2565 - val_mae: 35.9706\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.2618 - mse: 1246.2618 - mae: 35.0000 - val_loss: 1310.2212 - val_mse: 1310.2212 - val_mae: 35.9706\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.2659 - mse: 1246.2659 - mae: 35.0000 - val_loss: 1310.2549 - val_mse: 1310.2549 - val_mae: 35.9706\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.2543 - mse: 1246.2543 - mae: 35.0000 - val_loss: 1310.2408 - val_mse: 1310.2408 - val_mae: 35.9706\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.2515 - mse: 1246.2515 - mae: 35.0000 - val_loss: 1310.2313 - val_mse: 1310.2313 - val_mae: 35.9706\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.2515 - mse: 1246.2515 - mae: 35.0000 - val_loss: 1310.2006 - val_mse: 1310.2006 - val_mae: 35.9706\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.2517 - mse: 1246.2517 - mae: 35.0000 - val_loss: 1310.1683 - val_mse: 1310.1683 - val_mae: 35.9706\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.2454 - mse: 1246.2454 - mae: 35.0000 - val_loss: 1310.1617 - val_mse: 1310.1617 - val_mae: 35.9706\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.2432 - mse: 1246.2432 - mae: 35.0000 - val_loss: 1310.1852 - val_mse: 1310.1852 - val_mae: 35.9706\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1246.2417 - mse: 1246.2417 - mae: 35.0000 - val_loss: 1310.2128 - val_mse: 1310.2128 - val_mae: 35.9706\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.2368 - mse: 1246.2368 - mae: 35.0000 - val_loss: 1310.2148 - val_mse: 1310.2148 - val_mae: 35.9706\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.2346 - mse: 1246.2346 - mae: 35.0000 - val_loss: 1310.2185 - val_mse: 1310.2185 - val_mae: 35.9706\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.2322 - mse: 1246.2322 - mae: 35.0000 - val_loss: 1310.2301 - val_mse: 1310.2301 - val_mae: 35.9706\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.2308 - mse: 1246.2308 - mae: 35.0000 - val_loss: 1310.2148 - val_mse: 1310.2148 - val_mae: 35.9706\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.2273 - mse: 1246.2273 - mae: 35.0000 - val_loss: 1310.2142 - val_mse: 1310.2142 - val_mae: 35.9706\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.2288 - mse: 1246.2288 - mae: 35.0000 - val_loss: 1310.1907 - val_mse: 1310.1907 - val_mae: 35.9706\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.2234 - mse: 1246.2234 - mae: 35.0000 - val_loss: 1310.1858 - val_mse: 1310.1858 - val_mae: 35.9706\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.2206 - mse: 1246.2206 - mae: 35.0000 - val_loss: 1310.2073 - val_mse: 1310.2073 - val_mae: 35.9706\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.2183 - mse: 1246.2183 - mae: 35.0000 - val_loss: 1310.2288 - val_mse: 1310.2288 - val_mae: 35.9706\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1246.2161 - mse: 1246.2161 - mae: 35.0000 - val_loss: 1310.2462 - val_mse: 1310.2462 - val_mae: 35.9706\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.2190 - mse: 1246.2190 - mae: 35.0000 - val_loss: 1310.2100 - val_mse: 1310.2100 - val_mae: 35.9706\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.2107 - mse: 1246.2107 - mae: 35.0000 - val_loss: 1310.2042 - val_mse: 1310.2042 - val_mae: 35.9706\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.2078 - mse: 1246.2078 - mae: 35.0000 - val_loss: 1310.2047 - val_mse: 1310.2047 - val_mae: 35.9706\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.2053 - mse: 1246.2053 - mae: 35.0000 - val_loss: 1310.2080 - val_mse: 1310.2080 - val_mae: 35.9706\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.2029 - mse: 1246.2029 - mae: 35.0000 - val_loss: 1310.2089 - val_mse: 1310.2089 - val_mae: 35.9706\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1246.2051 - mse: 1246.2051 - mae: 35.0000 - val_loss: 1310.2372 - val_mse: 1310.2372 - val_mae: 35.9706\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.1986 - mse: 1246.1986 - mae: 35.0000 - val_loss: 1310.2250 - val_mse: 1310.2250 - val_mae: 35.9706\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.2000 - mse: 1246.2000 - mae: 35.0000 - val_loss: 1310.2440 - val_mse: 1310.2440 - val_mae: 35.9706\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.1956 - mse: 1246.1956 - mae: 35.0000 - val_loss: 1310.2454 - val_mse: 1310.2454 - val_mae: 35.9706\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.1960 - mse: 1246.1960 - mae: 35.0000 - val_loss: 1310.2552 - val_mse: 1310.2552 - val_mae: 35.9706\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.1908 - mse: 1246.1908 - mae: 35.0000 - val_loss: 1310.2145 - val_mse: 1310.2145 - val_mae: 35.9706\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.1881 - mse: 1246.1881 - mae: 35.0000 - val_loss: 1310.2111 - val_mse: 1310.2111 - val_mae: 35.9706\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.1843 - mse: 1246.1843 - mae: 35.0000 - val_loss: 1310.1868 - val_mse: 1310.1868 - val_mae: 35.9706\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1246.1833 - mse: 1246.1833 - mae: 35.0000 - val_loss: 1310.1838 - val_mse: 1310.1838 - val_mae: 35.9706\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1246.1881 - mse: 1246.1881 - mae: 35.0000 - val_loss: 1310.1244 - val_mse: 1310.1244 - val_mae: 35.9706\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1246.1780 - mse: 1246.1780 - mae: 35.0000 - val_loss: 1310.1063 - val_mse: 1310.1063 - val_mae: 35.9706\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.1770 - mse: 1246.1770 - mae: 35.0000 - val_loss: 1310.1205 - val_mse: 1310.1205 - val_mae: 35.9706\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.1866 - mse: 1246.1866 - mae: 35.0000 - val_loss: 1310.0686 - val_mse: 1310.0686 - val_mae: 35.9706\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.1785 - mse: 1246.1785 - mae: 35.0000 - val_loss: 1310.0448 - val_mse: 1310.0448 - val_mae: 35.9706\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.1693 - mse: 1246.1693 - mae: 35.0000 - val_loss: 1310.0731 - val_mse: 1310.0731 - val_mae: 35.9706\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.1670 - mse: 1246.1670 - mae: 35.0000 - val_loss: 1310.0875 - val_mse: 1310.0875 - val_mae: 35.9706\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.1646 - mse: 1246.1646 - mae: 35.0000 - val_loss: 1310.1219 - val_mse: 1310.1219 - val_mae: 35.9706\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.1633 - mse: 1246.1633 - mae: 35.0000 - val_loss: 1310.1232 - val_mse: 1310.1232 - val_mae: 35.9706\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.1648 - mse: 1246.1648 - mae: 35.0000 - val_loss: 1310.1764 - val_mse: 1310.1764 - val_mae: 35.9706\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.1599 - mse: 1246.1599 - mae: 35.0000 - val_loss: 1310.2090 - val_mse: 1310.2090 - val_mae: 35.9706\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.1570 - mse: 1246.1570 - mae: 35.0000 - val_loss: 1310.1941 - val_mse: 1310.1941 - val_mae: 35.9706\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.1533 - mse: 1246.1533 - mae: 35.0000 - val_loss: 1310.2021 - val_mse: 1310.2021 - val_mae: 35.9706\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.1572 - mse: 1246.1572 - mae: 35.0000 - val_loss: 1310.2334 - val_mse: 1310.2334 - val_mae: 35.9706\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1246.1505 - mse: 1246.1505 - mae: 35.0000 - val_loss: 1310.2021 - val_mse: 1310.2021 - val_mae: 35.9706\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1246.1519 - mse: 1246.1519 - mae: 35.0000 - val_loss: 1310.2209 - val_mse: 1310.2209 - val_mae: 35.9706\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.1448 - mse: 1246.1448 - mae: 35.0000 - val_loss: 1310.2036 - val_mse: 1310.2036 - val_mae: 35.9706\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.1431 - mse: 1246.1431 - mae: 35.0000 - val_loss: 1310.1937 - val_mse: 1310.1937 - val_mae: 35.9706\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.1453 - mse: 1246.1453 - mae: 35.0000 - val_loss: 1310.1361 - val_mse: 1310.1361 - val_mae: 35.9706\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.1376 - mse: 1246.1376 - mae: 35.0000 - val_loss: 1310.1141 - val_mse: 1310.1141 - val_mae: 35.9706\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1246.1364 - mse: 1246.1364 - mae: 35.0000 - val_loss: 1310.1178 - val_mse: 1310.1178 - val_mae: 35.9706\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1246.1345 - mse: 1246.1345 - mae: 35.0000 - val_loss: 1310.0873 - val_mse: 1310.0873 - val_mae: 35.9706\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1246.1313 - mse: 1246.1313 - mae: 35.0000 - val_loss: 1310.0859 - val_mse: 1310.0859 - val_mae: 35.9706\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1246.1290 - mse: 1246.1290 - mae: 35.0000 - val_loss: 1310.0779 - val_mse: 1310.0779 - val_mae: 35.9706\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.1272 - mse: 1246.1272 - mae: 35.0000 - val_loss: 1310.0684 - val_mse: 1310.0684 - val_mae: 35.9706\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1246.1304 - mse: 1246.1304 - mae: 35.0000 - val_loss: 1310.1036 - val_mse: 1310.1036 - val_mae: 35.9706\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.1318 - mse: 1246.1318 - mae: 35.0000 - val_loss: 1310.0596 - val_mse: 1310.0596 - val_mae: 35.9706\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.1208 - mse: 1246.1208 - mae: 35.0000 - val_loss: 1310.0636 - val_mse: 1310.0636 - val_mae: 35.9706\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1246.1227 - mse: 1246.1227 - mae: 35.0000 - val_loss: 1310.1012 - val_mse: 1310.1012 - val_mae: 35.9706\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.1174 - mse: 1246.1174 - mae: 35.0000 - val_loss: 1310.1206 - val_mse: 1310.1206 - val_mae: 35.9706\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.1240 - mse: 1246.1240 - mae: 35.0000 - val_loss: 1310.0760 - val_mse: 1310.0760 - val_mae: 35.9706\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 1246.1122 - mse: 1246.1122 - mae: 35.0000 - val_loss: 1310.0895 - val_mse: 1310.0895 - val_mae: 35.9706\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.1101 - mse: 1246.1101 - mae: 35.0000 - val_loss: 1310.1010 - val_mse: 1310.1010 - val_mae: 35.9706\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.1094 - mse: 1246.1094 - mae: 35.0000 - val_loss: 1310.1208 - val_mse: 1310.1208 - val_mae: 35.9706\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.1072 - mse: 1246.1072 - mae: 35.0000 - val_loss: 1310.1350 - val_mse: 1310.1350 - val_mae: 35.9706\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.1038 - mse: 1246.1038 - mae: 35.0000 - val_loss: 1310.1312 - val_mse: 1310.1312 - val_mae: 35.9706\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1246.1069 - mse: 1246.1069 - mae: 35.0000 - val_loss: 1310.1553 - val_mse: 1310.1553 - val_mae: 35.9706\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.0999 - mse: 1246.0999 - mae: 35.0000 - val_loss: 1310.1421 - val_mse: 1310.1421 - val_mae: 35.9706\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.0988 - mse: 1246.0988 - mae: 35.0000 - val_loss: 1310.1117 - val_mse: 1310.1117 - val_mae: 35.9706\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.0958 - mse: 1246.0958 - mae: 35.0000 - val_loss: 1310.0992 - val_mse: 1310.0992 - val_mae: 35.9706\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.0968 - mse: 1246.0968 - mae: 35.0000 - val_loss: 1310.1110 - val_mse: 1310.1110 - val_mae: 35.9706\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.0918 - mse: 1246.0918 - mae: 35.0000 - val_loss: 1310.0870 - val_mse: 1310.0870 - val_mae: 35.9706\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.0903 - mse: 1246.0903 - mae: 35.0000 - val_loss: 1310.0582 - val_mse: 1310.0582 - val_mae: 35.9706\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.0886 - mse: 1246.0886 - mae: 35.0000 - val_loss: 1310.0381 - val_mse: 1310.0381 - val_mae: 35.9706\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.1022 - mse: 1246.1022 - mae: 35.0000 - val_loss: 1310.0913 - val_mse: 1310.0913 - val_mae: 35.9706\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.0847 - mse: 1246.0847 - mae: 35.0000 - val_loss: 1310.0941 - val_mse: 1310.0941 - val_mae: 35.9706\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1246.0828 - mse: 1246.0828 - mae: 35.0000 - val_loss: 1310.0607 - val_mse: 1310.0607 - val_mae: 35.9706\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.0800 - mse: 1246.0800 - mae: 35.0000 - val_loss: 1310.0391 - val_mse: 1310.0391 - val_mae: 35.9706\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.0815 - mse: 1246.0815 - mae: 35.0000 - val_loss: 1310.0062 - val_mse: 1310.0062 - val_mae: 35.9706\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.0764 - mse: 1246.0764 - mae: 35.0000 - val_loss: 1309.9979 - val_mse: 1309.9979 - val_mae: 35.9706\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.0740 - mse: 1246.0740 - mae: 35.0000 - val_loss: 1310.0099 - val_mse: 1310.0099 - val_mae: 35.9706\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1246.0720 - mse: 1246.0720 - mae: 35.0000 - val_loss: 1310.0244 - val_mse: 1310.0244 - val_mae: 35.9706\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.0706 - mse: 1246.0706 - mae: 35.0000 - val_loss: 1310.0212 - val_mse: 1310.0212 - val_mae: 35.9706\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.0681 - mse: 1246.0681 - mae: 35.0000 - val_loss: 1310.0392 - val_mse: 1310.0392 - val_mae: 35.9706\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.0687 - mse: 1246.0687 - mae: 35.0000 - val_loss: 1310.0244 - val_mse: 1310.0244 - val_mae: 35.9706\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1246.0681 - mse: 1246.0681 - mae: 35.0000 - val_loss: 1310.0081 - val_mse: 1310.0081 - val_mae: 35.9706\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.0645 - mse: 1246.0645 - mae: 35.0000 - val_loss: 1310.0479 - val_mse: 1310.0479 - val_mae: 35.9706\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.0684 - mse: 1246.0684 - mae: 35.0000 - val_loss: 1310.0186 - val_mse: 1310.0186 - val_mae: 35.9706\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1246.0596 - mse: 1246.0596 - mae: 35.0000 - val_loss: 1310.0540 - val_mse: 1310.0540 - val_mae: 35.9706\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.0565 - mse: 1246.0565 - mae: 35.0000 - val_loss: 1310.0701 - val_mse: 1310.0701 - val_mae: 35.9706\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.0544 - mse: 1246.0544 - mae: 35.0000 - val_loss: 1310.0791 - val_mse: 1310.0791 - val_mae: 35.9706\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.0560 - mse: 1246.0560 - mae: 35.0000 - val_loss: 1310.0557 - val_mse: 1310.0557 - val_mae: 35.9706\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.0505 - mse: 1246.0505 - mae: 35.0000 - val_loss: 1310.0619 - val_mse: 1310.0619 - val_mae: 35.9706\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1246.0497 - mse: 1246.0497 - mae: 35.0000 - val_loss: 1310.0770 - val_mse: 1310.0770 - val_mae: 35.9706\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.0474 - mse: 1246.0474 - mae: 35.0000 - val_loss: 1310.0853 - val_mse: 1310.0853 - val_mae: 35.9706\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.0450 - mse: 1246.0450 - mae: 35.0000 - val_loss: 1310.0793 - val_mse: 1310.0793 - val_mae: 35.9706\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.0513 - mse: 1246.0513 - mae: 35.0000 - val_loss: 1310.1106 - val_mse: 1310.1106 - val_mae: 35.9706\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.0427 - mse: 1246.0427 - mae: 35.0000 - val_loss: 1310.0747 - val_mse: 1310.0747 - val_mae: 35.9706\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.0425 - mse: 1246.0425 - mae: 35.0000 - val_loss: 1310.0328 - val_mse: 1310.0328 - val_mae: 35.9706\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.0376 - mse: 1246.0376 - mae: 35.0000 - val_loss: 1310.0177 - val_mse: 1310.0177 - val_mae: 35.9706\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1246.0388 - mse: 1246.0388 - mae: 35.0000 - val_loss: 1310.0342 - val_mse: 1310.0342 - val_mae: 35.9706\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1246.0378 - mse: 1246.0378 - mae: 35.0000 - val_loss: 1310.0492 - val_mse: 1310.0492 - val_mae: 35.9706\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.0327 - mse: 1246.0327 - mae: 35.0000 - val_loss: 1310.0438 - val_mse: 1310.0438 - val_mae: 35.9706\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.0304 - mse: 1246.0304 - mae: 35.0000 - val_loss: 1310.0179 - val_mse: 1310.0179 - val_mae: 35.9706\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1246.0281 - mse: 1246.0281 - mae: 35.0000 - val_loss: 1310.0018 - val_mse: 1310.0018 - val_mae: 35.9706\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.0273 - mse: 1246.0273 - mae: 35.0000 - val_loss: 1309.9758 - val_mse: 1309.9758 - val_mae: 35.9706\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.0254 - mse: 1246.0254 - mae: 35.0000 - val_loss: 1309.9600 - val_mse: 1309.9600 - val_mae: 35.9706\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.0234 - mse: 1246.0234 - mae: 35.0000 - val_loss: 1309.9651 - val_mse: 1309.9651 - val_mae: 35.9706\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.0254 - mse: 1246.0254 - mae: 35.0000 - val_loss: 1309.9357 - val_mse: 1309.9357 - val_mae: 35.9706\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.0222 - mse: 1246.0222 - mae: 35.0000 - val_loss: 1309.9656 - val_mse: 1309.9656 - val_mae: 35.9706\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1246.0178 - mse: 1246.0178 - mae: 35.0000 - val_loss: 1309.9777 - val_mse: 1309.9777 - val_mae: 35.9706\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1246.0186 - mse: 1246.0186 - mae: 35.0000 - val_loss: 1309.9580 - val_mse: 1309.9580 - val_mae: 35.9706\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1246.0155 - mse: 1246.0155 - mae: 35.0000 - val_loss: 1309.9515 - val_mse: 1309.9515 - val_mae: 35.9706\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.0159 - mse: 1246.0159 - mae: 35.0000 - val_loss: 1309.9385 - val_mse: 1309.9385 - val_mae: 35.9706\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1246.0105 - mse: 1246.0105 - mae: 35.0000 - val_loss: 1309.9543 - val_mse: 1309.9543 - val_mae: 35.9706\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1246.0085 - mse: 1246.0085 - mae: 35.0000 - val_loss: 1309.9709 - val_mse: 1309.9709 - val_mae: 35.9706\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1246.0076 - mse: 1246.0076 - mae: 35.0000 - val_loss: 1309.9971 - val_mse: 1309.9971 - val_mae: 35.9706\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1246.0059 - mse: 1246.0059 - mae: 35.0000 - val_loss: 1310.0214 - val_mse: 1310.0214 - val_mae: 35.9706\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.0038 - mse: 1246.0038 - mae: 35.0000 - val_loss: 1310.0322 - val_mse: 1310.0322 - val_mae: 35.9706\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.0038 - mse: 1246.0038 - mae: 35.0000 - val_loss: 1310.0145 - val_mse: 1310.0145 - val_mae: 35.9706\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1246.0007 - mse: 1246.0007 - mae: 35.0000 - val_loss: 1310.0276 - val_mse: 1310.0276 - val_mae: 35.9706\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1245.9988 - mse: 1245.9988 - mae: 35.0000 - val_loss: 1310.0189 - val_mse: 1310.0189 - val_mae: 35.9706\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1246.0006 - mse: 1246.0006 - mae: 35.0000 - val_loss: 1309.9866 - val_mse: 1309.9866 - val_mae: 35.9706\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1245.9949 - mse: 1245.9949 - mae: 35.0000 - val_loss: 1309.9878 - val_mse: 1309.9878 - val_mae: 35.9706\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1245.9983 - mse: 1245.9983 - mae: 35.0000 - val_loss: 1310.0186 - val_mse: 1310.0186 - val_mae: 35.9706\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1245.9923 - mse: 1245.9923 - mae: 35.0000 - val_loss: 1310.0194 - val_mse: 1310.0194 - val_mae: 35.9706\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1245.9902 - mse: 1245.9902 - mae: 35.0000 - val_loss: 1310.0073 - val_mse: 1310.0073 - val_mae: 35.9706\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1245.9958 - mse: 1245.9958 - mae: 35.0000 - val_loss: 1309.9537 - val_mse: 1309.9537 - val_mae: 35.9706\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1245.9916 - mse: 1245.9916 - mae: 35.0000 - val_loss: 1309.9166 - val_mse: 1309.9166 - val_mae: 35.9706\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1245.9883 - mse: 1245.9883 - mae: 35.0000 - val_loss: 1309.8958 - val_mse: 1309.8958 - val_mae: 35.9706\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1245.9866 - mse: 1245.9866 - mae: 35.0000 - val_loss: 1309.9333 - val_mse: 1309.9333 - val_mae: 35.9706\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1245.9841 - mse: 1245.9841 - mae: 35.0000 - val_loss: 1309.9625 - val_mse: 1309.9625 - val_mae: 35.9706\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1245.9801 - mse: 1245.9801 - mae: 35.0000 - val_loss: 1309.9642 - val_mse: 1309.9642 - val_mae: 35.9706\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1245.9951 - mse: 1245.9951 - mae: 35.0000 - val_loss: 1310.0229 - val_mse: 1310.0229 - val_mae: 35.9706\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1245.9780 - mse: 1245.9780 - mae: 35.0000 - val_loss: 1310.0232 - val_mse: 1310.0232 - val_mae: 35.9706\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1245.9761 - mse: 1245.9761 - mae: 35.0000 - val_loss: 1309.9926 - val_mse: 1309.9926 - val_mae: 35.9706\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1245.9733 - mse: 1245.9733 - mae: 35.0000 - val_loss: 1309.9779 - val_mse: 1309.9779 - val_mae: 35.9706\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1245.9719 - mse: 1245.9719 - mae: 35.0000 - val_loss: 1309.9695 - val_mse: 1309.9695 - val_mae: 35.9706\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1245.9836 - mse: 1245.9836 - mae: 35.0000 - val_loss: 1309.8992 - val_mse: 1309.8992 - val_mae: 35.9706\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1245.9707 - mse: 1245.9707 - mae: 35.0000 - val_loss: 1309.8760 - val_mse: 1309.8760 - val_mae: 35.9706\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1245.9711 - mse: 1245.9711 - mae: 35.0000 - val_loss: 1309.9078 - val_mse: 1309.9078 - val_mae: 35.9706\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1245.9656 - mse: 1245.9656 - mae: 35.0000 - val_loss: 1309.9166 - val_mse: 1309.9166 - val_mae: 35.9706\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1245.9675 - mse: 1245.9675 - mae: 35.0000 - val_loss: 1309.8894 - val_mse: 1309.8894 - val_mae: 35.9706\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1245.9626 - mse: 1245.9626 - mae: 35.0000 - val_loss: 1309.9015 - val_mse: 1309.9015 - val_mae: 35.9706\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1245.9622 - mse: 1245.9622 - mae: 35.0000 - val_loss: 1309.9260 - val_mse: 1309.9260 - val_mae: 35.9706\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1245.9587 - mse: 1245.9587 - mae: 35.0000 - val_loss: 1309.9307 - val_mse: 1309.9307 - val_mae: 35.9706\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1245.9580 - mse: 1245.9580 - mae: 35.0000 - val_loss: 1309.9426 - val_mse: 1309.9426 - val_mae: 35.9706\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1245.9579 - mse: 1245.9579 - mae: 35.0000 - val_loss: 1309.9214 - val_mse: 1309.9214 - val_mae: 35.9706\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1245.9541 - mse: 1245.9541 - mae: 35.0000 - val_loss: 1309.9230 - val_mse: 1309.9230 - val_mae: 35.9706\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1245.9556 - mse: 1245.9556 - mae: 35.0000 - val_loss: 1309.9510 - val_mse: 1309.9510 - val_mae: 35.9706\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1245.9514 - mse: 1245.9514 - mae: 35.0000 - val_loss: 1309.9487 - val_mse: 1309.9487 - val_mae: 35.9706\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1245.9500 - mse: 1245.9500 - mae: 35.0000 - val_loss: 1309.9506 - val_mse: 1309.9506 - val_mae: 35.9706\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1245.9507 - mse: 1245.9507 - mae: 35.0000 - val_loss: 1309.9655 - val_mse: 1309.9655 - val_mae: 35.9706\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1245.9465 - mse: 1245.9465 - mae: 35.0000 - val_loss: 1309.9500 - val_mse: 1309.9500 - val_mae: 35.9706\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1245.9457 - mse: 1245.9457 - mae: 35.0000 - val_loss: 1309.9470 - val_mse: 1309.9470 - val_mae: 35.9706\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1245.9487 - mse: 1245.9487 - mae: 35.0000 - val_loss: 1309.8981 - val_mse: 1309.8981 - val_mae: 35.9706\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1245.9421 - mse: 1245.9421 - mae: 35.0000 - val_loss: 1309.8958 - val_mse: 1309.8958 - val_mae: 35.9706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWNOnduwSPXJ",
        "outputId": "86a6fe0c-bc83-4898-dc7d-8462ee58f96d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test, batch_size=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9IYU67DRu7u",
        "outputId": "77772359-5aeb-409d-b2e5-6739996083fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 3ms/step - loss: 1281.2804 - mse: 1281.2804 - mae: 35.5972\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1281.2803955078125, 1281.2803955078125, 35.59722137451172]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test).flatten()\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i57-t2PCSGFc",
        "outputId": "1a9e5f63-cc3a-4b42-c1ec-c13690623c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([40.238037, 31.861353, 45.200584, 47.93135 , 37.585922, 45.200584,\n",
              "       48.273033, 48.273033, 46.27716 , 45.200584, 44.045372, 50.66211 ,\n",
              "       47.055084, 45.043312, 41.89222 , 45.12195 , 43.54641 , 46.854767,\n",
              "       48.430313, 44.465706, 43.54641 , 45.62092 , 33.095207, 41.89222 ,\n",
              "       42.811516, 46.27716 , 42.968796, 44.465706, 46.43199 , 46.61885 ,\n",
              "       48.273033, 39.240105, 44.701622, 43.96673 , 44.62298 , 48.50895 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res_keras = model.predict(np.array([[50,32]]))\n",
        "res_keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9HvFOleTchx",
        "outputId": "8d45ab7a-4f92-43ee-e767-cd023b66b569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[45.200584]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UlrmKex5TO49",
        "outputId": "5f1ff870-05d7-4438-edf9-871d8c8c1fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Internal Marks  External Marks\n",
              "69               44              29\n",
              "46               39              18\n",
              "58               50              32\n",
              "114              53              34\n",
              "73               42              26\n",
              "98               50              32\n",
              "31               51              37\n",
              "53               51              37\n",
              "65               51              33\n",
              "96               50              32\n",
              "95               48              32\n",
              "97               56              36\n",
              "2                49              37\n",
              "62               48              34\n",
              "110              46              30\n",
              "55               49              33\n",
              "103              48              31\n",
              "100              52              33\n",
              "66               53              35\n",
              "44               47              34\n",
              "77               48              31\n",
              "17               49              34\n",
              "81               42              17\n",
              "74               46              30\n",
              "56               45              33\n",
              "94               51              33\n",
              "35               47              31\n",
              "38               47              34\n",
              "93               48              37\n",
              "48               49              36\n",
              "33               51              37\n",
              "59               44              27\n",
              "92               50              31\n",
              "42               47              33\n",
              "10               49              32\n",
              "85               54              34"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ac4d04c-82ea-4b67-8195-fcd7d18de1a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Internal Marks</th>\n",
              "      <th>External Marks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>44</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>39</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>53</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>42</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>51</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>51</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>51</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>48</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>56</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>49</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>48</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>46</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>49</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>48</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>52</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>53</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>48</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>49</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>42</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>46</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>45</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>51</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>47</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>48</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>49</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>51</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>44</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>50</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>47</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>49</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>54</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ac4d04c-82ea-4b67-8195-fcd7d18de1a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ac4d04c-82ea-4b67-8195-fcd7d18de1a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ac4d04c-82ea-4b67-8195-fcd7d18de1a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mgH-5lMGS_61",
        "outputId": "f9df9351-c2b8-4798-9d4e-9fa4c58956f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Total  Grade_Point\n",
              "69      74            8\n",
              "46      57            7\n",
              "58      82            9\n",
              "114     79            9\n",
              "73      73            8\n",
              "98      81            9\n",
              "31      85            9\n",
              "53      83            9\n",
              "65      82            9\n",
              "96      81            9\n",
              "95      81            9\n",
              "97      92           10\n",
              "2       88            9\n",
              "62      82            9\n",
              "110     68            8\n",
              "55      83            9\n",
              "103     80            9\n",
              "100     80            9\n",
              "66      82            9\n",
              "44      84            9\n",
              "77      82            9\n",
              "17      87            9\n",
              "81      59            7\n",
              "74      73            8\n",
              "56      76            8\n",
              "94      81            9\n",
              "35      78            8\n",
              "38      85            9\n",
              "93      81            9\n",
              "48      83            9\n",
              "33      85            9\n",
              "59      76            8\n",
              "92      81            9\n",
              "42      85            9\n",
              "10      87            9\n",
              "85      81            9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f6efad5-28c3-4611-a2e0-1ba48c158aae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>Grade_Point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>74</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>57</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>82</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>73</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>81</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>85</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>83</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>82</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>81</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>81</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>92</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>88</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>82</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>68</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>83</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>80</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>80</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>82</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>84</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>82</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>87</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>59</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>73</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>76</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>81</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>78</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>85</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>81</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>83</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>85</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>76</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>81</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>85</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>87</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>81</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f6efad5-28c3-4611-a2e0-1ba48c158aae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f6efad5-28c3-4611-a2e0-1ba48c158aae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f6efad5-28c3-4611-a2e0-1ba48c158aae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras_file = \"se_project.h5\"\n",
        "tf.keras.models.save_model()"
      ],
      "metadata": {
        "id": "yXOZ6GR3L29C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "daBjELUXMT-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = lr.fit(x_train,y_train)\n",
        "\n",
        "# create a TF model with the same architecture\n",
        "tf_model = tf.keras.models.Sequential()\n",
        "tf_model.add(tf.keras.Input(shape=(2,)))\n",
        "tf_model.add(tf.keras.layers.Dense(2))\n",
        "\n",
        "# assign the parameters from sklearn to the TF model\n",
        "tf_model.layers[0].weights[0].assign(model.coef_.transpose())\n",
        "tf_model.layers[0].bias.assign(model.intercept_)\n",
        "\n",
        "# verify the models do the same prediction\n",
        "#assert np.all((tf_model(x) > 0)[:, 0].numpy() == model.predict(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBqOGfNIVtAQ",
        "outputId": "583105c6-467f-4fe9-af78-46728a7a070b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2,) dtype=float32, numpy=array([25.631708 ,  1.6959783], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])"
      ],
      "metadata": {
        "id": "fzVqt0WcXT17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_model = tf_model.fit(x_train, y_train, epochs=500, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hYFgED1XbMz",
        "outputId": "b24a34fd-6195-402d-de94-a520eac06934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 1s 248ms/step - loss: 8.4229 - mse: 8.4229 - mae: 1.7086 - val_loss: 9.3449 - val_mse: 9.3449 - val_mae: 1.9183\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3595 - mse: 8.3595 - mae: 1.7016 - val_loss: 9.5094 - val_mse: 9.5094 - val_mae: 1.9178\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3421 - mse: 8.3421 - mae: 1.7015 - val_loss: 9.6901 - val_mse: 9.6901 - val_mae: 1.9254\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3096 - mse: 8.3096 - mae: 1.6997 - val_loss: 9.8111 - val_mse: 9.8111 - val_mae: 1.9306\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3246 - mse: 8.3246 - mae: 1.6992 - val_loss: 9.9640 - val_mse: 9.9640 - val_mae: 1.9448\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3015 - mse: 8.3015 - mae: 1.6969 - val_loss: 10.0527 - val_mse: 10.0527 - val_mae: 1.9526\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3132 - mse: 8.3132 - mae: 1.6998 - val_loss: 10.1486 - val_mse: 10.1486 - val_mae: 1.9587\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3065 - mse: 8.3065 - mae: 1.6997 - val_loss: 10.1554 - val_mse: 10.1554 - val_mae: 1.9553\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 8.3034 - mse: 8.3034 - mae: 1.6995 - val_loss: 10.1772 - val_mse: 10.1772 - val_mae: 1.9562\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3049 - mse: 8.3049 - mae: 1.7006 - val_loss: 10.1965 - val_mse: 10.1965 - val_mae: 1.9565\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 8.3086 - mse: 8.3086 - mae: 1.7013 - val_loss: 10.1817 - val_mse: 10.1817 - val_mae: 1.9565\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3108 - mse: 8.3108 - mae: 1.7012 - val_loss: 10.2123 - val_mse: 10.2123 - val_mae: 1.9624\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 8.3074 - mse: 8.3074 - mae: 1.6993 - val_loss: 10.1881 - val_mse: 10.1881 - val_mae: 1.9616\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3046 - mse: 8.3046 - mae: 1.6989 - val_loss: 10.1761 - val_mse: 10.1761 - val_mae: 1.9598\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3075 - mse: 8.3075 - mae: 1.6996 - val_loss: 10.1393 - val_mse: 10.1393 - val_mae: 1.9542\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3062 - mse: 8.3062 - mae: 1.6999 - val_loss: 10.1438 - val_mse: 10.1438 - val_mae: 1.9540\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3042 - mse: 8.3042 - mae: 1.6999 - val_loss: 10.1159 - val_mse: 10.1159 - val_mae: 1.9514\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 8.3028 - mse: 8.3028 - mae: 1.6996 - val_loss: 10.1004 - val_mse: 10.1004 - val_mae: 1.9518\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3108 - mse: 8.3108 - mae: 1.6998 - val_loss: 10.0559 - val_mse: 10.0559 - val_mae: 1.9498\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3034 - mse: 8.3034 - mae: 1.6979 - val_loss: 10.0376 - val_mse: 10.0376 - val_mae: 1.9499\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3042 - mse: 8.3042 - mae: 1.6984 - val_loss: 10.0459 - val_mse: 10.0459 - val_mae: 1.9517\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3025 - mse: 8.3025 - mae: 1.6979 - val_loss: 10.0346 - val_mse: 10.0346 - val_mae: 1.9493\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3024 - mse: 8.3024 - mae: 1.6980 - val_loss: 10.0287 - val_mse: 10.0287 - val_mae: 1.9468\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3024 - mse: 8.3024 - mae: 1.6984 - val_loss: 10.0226 - val_mse: 10.0226 - val_mae: 1.9455\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3031 - mse: 8.3031 - mae: 1.6990 - val_loss: 10.0294 - val_mse: 10.0294 - val_mae: 1.9472\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3025 - mse: 8.3025 - mae: 1.6982 - val_loss: 10.0318 - val_mse: 10.0318 - val_mae: 1.9479\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 8.3054 - mse: 8.3054 - mae: 1.6989 - val_loss: 10.0494 - val_mse: 10.0494 - val_mae: 1.9505\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3030 - mse: 8.3030 - mae: 1.6985 - val_loss: 10.0355 - val_mse: 10.0355 - val_mae: 1.9481\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3038 - mse: 8.3038 - mae: 1.6983 - val_loss: 10.0466 - val_mse: 10.0466 - val_mae: 1.9492\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3040 - mse: 8.3040 - mae: 1.6986 - val_loss: 10.0567 - val_mse: 10.0567 - val_mae: 1.9503\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3197 - mse: 8.3197 - mae: 1.7015 - val_loss: 10.0949 - val_mse: 10.0949 - val_mae: 1.9535\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3024 - mse: 8.3024 - mae: 1.6984 - val_loss: 10.0750 - val_mse: 10.0750 - val_mae: 1.9501\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3045 - mse: 8.3045 - mae: 1.6997 - val_loss: 10.0469 - val_mse: 10.0469 - val_mae: 1.9465\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3030 - mse: 8.3030 - mae: 1.6994 - val_loss: 10.0491 - val_mse: 10.0491 - val_mae: 1.9479\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3022 - mse: 8.3022 - mae: 1.6986 - val_loss: 10.0442 - val_mse: 10.0442 - val_mae: 1.9490\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3036 - mse: 8.3036 - mae: 1.6985 - val_loss: 10.0506 - val_mse: 10.0506 - val_mae: 1.9504\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 8.3030 - mse: 8.3030 - mae: 1.6983 - val_loss: 10.0518 - val_mse: 10.0518 - val_mae: 1.9509\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3025 - mse: 8.3025 - mae: 1.6981 - val_loss: 10.0372 - val_mse: 10.0372 - val_mae: 1.9493\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3022 - mse: 8.3022 - mae: 1.6986 - val_loss: 10.0279 - val_mse: 10.0279 - val_mae: 1.9461\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3031 - mse: 8.3031 - mae: 1.6989 - val_loss: 10.0334 - val_mse: 10.0334 - val_mae: 1.9459\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 8.3039 - mse: 8.3039 - mae: 1.6993 - val_loss: 10.0434 - val_mse: 10.0434 - val_mae: 1.9485\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3025 - mse: 8.3025 - mae: 1.6984 - val_loss: 10.0311 - val_mse: 10.0311 - val_mae: 1.9480\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3051 - mse: 8.3051 - mae: 1.6992 - val_loss: 10.0106 - val_mse: 10.0106 - val_mae: 1.9462\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3050 - mse: 8.3050 - mae: 1.6984 - val_loss: 9.9957 - val_mse: 9.9957 - val_mae: 1.9461\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3072 - mse: 8.3072 - mae: 1.6985 - val_loss: 10.0269 - val_mse: 10.0269 - val_mae: 1.9500\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3022 - mse: 8.3022 - mae: 1.6978 - val_loss: 10.0278 - val_mse: 10.0278 - val_mae: 1.9496\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3032 - mse: 8.3032 - mae: 1.6986 - val_loss: 10.0204 - val_mse: 10.0204 - val_mae: 1.9463\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3023 - mse: 8.3023 - mae: 1.6986 - val_loss: 10.0315 - val_mse: 10.0315 - val_mae: 1.9469\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3052 - mse: 8.3052 - mae: 1.6989 - val_loss: 10.0174 - val_mse: 10.0174 - val_mae: 1.9457\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3027 - mse: 8.3027 - mae: 1.6987 - val_loss: 10.0349 - val_mse: 10.0349 - val_mae: 1.9492\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3065 - mse: 8.3065 - mae: 1.6986 - val_loss: 10.0187 - val_mse: 10.0187 - val_mae: 1.9478\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3028 - mse: 8.3028 - mae: 1.6982 - val_loss: 10.0392 - val_mse: 10.0392 - val_mae: 1.9497\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3027 - mse: 8.3027 - mae: 1.6982 - val_loss: 10.0560 - val_mse: 10.0560 - val_mae: 1.9506\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 8.3027 - mse: 8.3027 - mae: 1.6985 - val_loss: 10.0693 - val_mse: 10.0693 - val_mae: 1.9498\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3024 - mse: 8.3024 - mae: 1.6990 - val_loss: 10.0633 - val_mse: 10.0633 - val_mae: 1.9484\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3020 - mse: 8.3020 - mae: 1.6994 - val_loss: 10.0654 - val_mse: 10.0654 - val_mae: 1.9487\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3020 - mse: 8.3020 - mae: 1.6991 - val_loss: 10.0716 - val_mse: 10.0716 - val_mae: 1.9505\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3054 - mse: 8.3054 - mae: 1.6988 - val_loss: 10.0514 - val_mse: 10.0514 - val_mae: 1.9499\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3018 - mse: 8.3018 - mae: 1.6982 - val_loss: 10.0553 - val_mse: 10.0553 - val_mae: 1.9516\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3180 - mse: 8.3180 - mae: 1.7007 - val_loss: 10.0136 - val_mse: 10.0136 - val_mae: 1.9471\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3050 - mse: 8.3050 - mae: 1.6982 - val_loss: 10.0425 - val_mse: 10.0425 - val_mae: 1.9493\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3054 - mse: 8.3054 - mae: 1.6988 - val_loss: 10.0690 - val_mse: 10.0690 - val_mae: 1.9518\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3022 - mse: 8.3022 - mae: 1.6987 - val_loss: 10.0627 - val_mse: 10.0627 - val_mae: 1.9499\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3079 - mse: 8.3079 - mae: 1.6995 - val_loss: 10.0375 - val_mse: 10.0375 - val_mae: 1.9468\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3049 - mse: 8.3049 - mae: 1.6992 - val_loss: 10.0629 - val_mse: 10.0629 - val_mae: 1.9502\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3025 - mse: 8.3025 - mae: 1.6987 - val_loss: 10.0741 - val_mse: 10.0741 - val_mae: 1.9525\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3034 - mse: 8.3034 - mae: 1.6988 - val_loss: 10.0584 - val_mse: 10.0584 - val_mae: 1.9501\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3038 - mse: 8.3038 - mae: 1.6990 - val_loss: 10.0737 - val_mse: 10.0737 - val_mae: 1.9520\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3040 - mse: 8.3040 - mae: 1.6988 - val_loss: 10.0859 - val_mse: 10.0859 - val_mae: 1.9520\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3036 - mse: 8.3036 - mae: 1.6990 - val_loss: 10.0931 - val_mse: 10.0931 - val_mae: 1.9516\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3021 - mse: 8.3021 - mae: 1.6993 - val_loss: 10.0754 - val_mse: 10.0754 - val_mae: 1.9491\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3047 - mse: 8.3047 - mae: 1.6999 - val_loss: 10.0853 - val_mse: 10.0853 - val_mae: 1.9514\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3019 - mse: 8.3019 - mae: 1.6987 - val_loss: 10.0791 - val_mse: 10.0791 - val_mae: 1.9512\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3028 - mse: 8.3028 - mae: 1.6992 - val_loss: 10.0788 - val_mse: 10.0788 - val_mae: 1.9514\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3020 - mse: 8.3020 - mae: 1.6987 - val_loss: 10.0569 - val_mse: 10.0569 - val_mae: 1.9492\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3015 - mse: 8.3015 - mae: 1.6986 - val_loss: 10.0458 - val_mse: 10.0458 - val_mae: 1.9486\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3026 - mse: 8.3026 - mae: 1.6989 - val_loss: 10.0484 - val_mse: 10.0484 - val_mae: 1.9493\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3030 - mse: 8.3030 - mae: 1.6989 - val_loss: 10.0521 - val_mse: 10.0521 - val_mae: 1.9500\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3027 - mse: 8.3027 - mae: 1.6986 - val_loss: 10.0292 - val_mse: 10.0292 - val_mae: 1.9467\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3017 - mse: 8.3017 - mae: 1.6991 - val_loss: 10.0211 - val_mse: 10.0211 - val_mae: 1.9455\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3019 - mse: 8.3019 - mae: 1.6987 - val_loss: 10.0138 - val_mse: 10.0138 - val_mae: 1.9461\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3018 - mse: 8.3018 - mae: 1.6983 - val_loss: 10.0104 - val_mse: 10.0104 - val_mae: 1.9474\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 8.3022 - mse: 8.3022 - mae: 1.6980 - val_loss: 10.0055 - val_mse: 10.0055 - val_mae: 1.9473\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3017 - mse: 8.3017 - mae: 1.6980 - val_loss: 10.0100 - val_mse: 10.0100 - val_mae: 1.9478\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3194 - mse: 8.3194 - mae: 1.7004 - val_loss: 10.0617 - val_mse: 10.0617 - val_mae: 1.9520\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3047 - mse: 8.3047 - mae: 1.7001 - val_loss: 10.0386 - val_mse: 10.0386 - val_mae: 1.9468\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3016 - mse: 8.3016 - mae: 1.6993 - val_loss: 10.0408 - val_mse: 10.0408 - val_mae: 1.9459\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3015 - mse: 8.3015 - mae: 1.6995 - val_loss: 10.0427 - val_mse: 10.0427 - val_mae: 1.9473\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 8.3038 - mse: 8.3038 - mae: 1.6989 - val_loss: 10.0294 - val_mse: 10.0294 - val_mae: 1.9482\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3033 - mse: 8.3033 - mae: 1.6982 - val_loss: 10.0508 - val_mse: 10.0508 - val_mae: 1.9518\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3063 - mse: 8.3063 - mae: 1.6991 - val_loss: 10.0289 - val_mse: 10.0289 - val_mae: 1.9486\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3024 - mse: 8.3024 - mae: 1.6985 - val_loss: 10.0462 - val_mse: 10.0462 - val_mae: 1.9492\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3027 - mse: 8.3027 - mae: 1.6993 - val_loss: 10.0380 - val_mse: 10.0380 - val_mae: 1.9471\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3026 - mse: 8.3026 - mae: 1.6990 - val_loss: 10.0327 - val_mse: 10.0327 - val_mae: 1.9476\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 8.3044 - mse: 8.3044 - mae: 1.6990 - val_loss: 10.0606 - val_mse: 10.0606 - val_mae: 1.9509\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3034 - mse: 8.3034 - mae: 1.6988 - val_loss: 10.0798 - val_mse: 10.0798 - val_mae: 1.9526\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3013 - mse: 8.3013 - mae: 1.6986 - val_loss: 10.0792 - val_mse: 10.0792 - val_mae: 1.9514\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3042 - mse: 8.3042 - mae: 1.6990 - val_loss: 10.0948 - val_mse: 10.0948 - val_mae: 1.9519\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3014 - mse: 8.3014 - mae: 1.6992 - val_loss: 10.0888 - val_mse: 10.0888 - val_mae: 1.9504\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3018 - mse: 8.3018 - mae: 1.6995 - val_loss: 10.0887 - val_mse: 10.0887 - val_mae: 1.9505\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3053 - mse: 8.3053 - mae: 1.6998 - val_loss: 10.1019 - val_mse: 10.1019 - val_mae: 1.9531\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3013 - mse: 8.3013 - mae: 1.6989 - val_loss: 10.0872 - val_mse: 10.0872 - val_mae: 1.9525\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3026 - mse: 8.3026 - mae: 1.6992 - val_loss: 10.0610 - val_mse: 10.0610 - val_mae: 1.9498\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3076 - mse: 8.3076 - mae: 1.6993 - val_loss: 10.0243 - val_mse: 10.0243 - val_mae: 1.9470\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3014 - mse: 8.3014 - mae: 1.6984 - val_loss: 10.0176 - val_mse: 10.0176 - val_mae: 1.9468\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3035 - mse: 8.3035 - mae: 1.6992 - val_loss: 10.0028 - val_mse: 10.0028 - val_mae: 1.9457\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3062 - mse: 8.3062 - mae: 1.6995 - val_loss: 10.0330 - val_mse: 10.0330 - val_mae: 1.9499\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3021 - mse: 8.3021 - mae: 1.6984 - val_loss: 10.0443 - val_mse: 10.0443 - val_mae: 1.9502\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3012 - mse: 8.3012 - mae: 1.6984 - val_loss: 10.0430 - val_mse: 10.0430 - val_mae: 1.9494\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3011 - mse: 8.3011 - mae: 1.6985 - val_loss: 10.0395 - val_mse: 10.0395 - val_mae: 1.9474\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 8.3118 - mse: 8.3118 - mae: 1.7015 - val_loss: 10.0761 - val_mse: 10.0761 - val_mae: 1.9507\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3039 - mse: 8.3039 - mae: 1.7010 - val_loss: 10.0530 - val_mse: 10.0530 - val_mae: 1.9465\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3013 - mse: 8.3013 - mae: 1.6999 - val_loss: 10.0556 - val_mse: 10.0556 - val_mae: 1.9479\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3021 - mse: 8.3021 - mae: 1.6990 - val_loss: 10.0667 - val_mse: 10.0667 - val_mae: 1.9513\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3010 - mse: 8.3010 - mae: 1.6986 - val_loss: 10.0601 - val_mse: 10.0601 - val_mae: 1.9520\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3021 - mse: 8.3021 - mae: 1.6984 - val_loss: 10.0452 - val_mse: 10.0452 - val_mae: 1.9508\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3125 - mse: 8.3125 - mae: 1.6998 - val_loss: 10.0065 - val_mse: 10.0065 - val_mae: 1.9455\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3016 - mse: 8.3016 - mae: 1.6987 - val_loss: 10.0208 - val_mse: 10.0208 - val_mae: 1.9469\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3011 - mse: 8.3011 - mae: 1.6988 - val_loss: 10.0293 - val_mse: 10.0293 - val_mae: 1.9470\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3088 - mse: 8.3088 - mae: 1.7015 - val_loss: 10.0652 - val_mse: 10.0652 - val_mae: 1.9521\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3064 - mse: 8.3064 - mae: 1.6991 - val_loss: 10.0891 - val_mse: 10.0891 - val_mae: 1.9529\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3105 - mse: 8.3105 - mae: 1.7004 - val_loss: 10.0486 - val_mse: 10.0486 - val_mae: 1.9471\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3022 - mse: 8.3022 - mae: 1.6997 - val_loss: 10.0378 - val_mse: 10.0378 - val_mae: 1.9456\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3018 - mse: 8.3018 - mae: 1.6999 - val_loss: 10.0522 - val_mse: 10.0522 - val_mae: 1.9486\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3072 - mse: 8.3072 - mae: 1.7005 - val_loss: 10.0808 - val_mse: 10.0808 - val_mae: 1.9539\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3019 - mse: 8.3019 - mae: 1.6989 - val_loss: 10.0854 - val_mse: 10.0854 - val_mae: 1.9538\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3032 - mse: 8.3032 - mae: 1.6995 - val_loss: 10.0611 - val_mse: 10.0611 - val_mae: 1.9490\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3013 - mse: 8.3013 - mae: 1.6996 - val_loss: 10.0500 - val_mse: 10.0500 - val_mae: 1.9467\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3018 - mse: 8.3018 - mae: 1.7000 - val_loss: 10.0597 - val_mse: 10.0597 - val_mae: 1.9483\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3016 - mse: 8.3016 - mae: 1.6995 - val_loss: 10.0481 - val_mse: 10.0481 - val_mae: 1.9483\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3016 - mse: 8.3016 - mae: 1.6987 - val_loss: 10.0395 - val_mse: 10.0395 - val_mae: 1.9500\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3018 - mse: 8.3018 - mae: 1.6985 - val_loss: 10.0313 - val_mse: 10.0313 - val_mae: 1.9500\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3041 - mse: 8.3041 - mae: 1.6989 - val_loss: 10.0540 - val_mse: 10.0540 - val_mae: 1.9510\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3029 - mse: 8.3029 - mae: 1.6988 - val_loss: 10.0372 - val_mse: 10.0372 - val_mae: 1.9481\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3075 - mse: 8.3075 - mae: 1.6994 - val_loss: 10.0680 - val_mse: 10.0680 - val_mae: 1.9496\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3125 - mse: 8.3125 - mae: 1.7009 - val_loss: 10.0291 - val_mse: 10.0291 - val_mae: 1.9450\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3031 - mse: 8.3031 - mae: 1.6998 - val_loss: 10.0198 - val_mse: 10.0198 - val_mae: 1.9457\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3009 - mse: 8.3009 - mae: 1.6991 - val_loss: 10.0337 - val_mse: 10.0337 - val_mae: 1.9495\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3008 - mse: 8.3008 - mae: 1.6985 - val_loss: 10.0387 - val_mse: 10.0387 - val_mae: 1.9503\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 8.3007 - mse: 8.3007 - mae: 1.6985 - val_loss: 10.0482 - val_mse: 10.0482 - val_mae: 1.9506\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3008 - mse: 8.3008 - mae: 1.6987 - val_loss: 10.0584 - val_mse: 10.0584 - val_mae: 1.9509\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3023 - mse: 8.3023 - mae: 1.6999 - val_loss: 10.0498 - val_mse: 10.0498 - val_mae: 1.9473\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3012 - mse: 8.3012 - mae: 1.6997 - val_loss: 10.0481 - val_mse: 10.0481 - val_mae: 1.9471\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3007 - mse: 8.3007 - mae: 1.6993 - val_loss: 10.0571 - val_mse: 10.0571 - val_mae: 1.9500\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3008 - mse: 8.3008 - mae: 1.6987 - val_loss: 10.0579 - val_mse: 10.0579 - val_mae: 1.9510\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 8.3009 - mse: 8.3009 - mae: 1.6990 - val_loss: 10.0693 - val_mse: 10.0693 - val_mae: 1.9523\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 8.3007 - mse: 8.3007 - mae: 1.6988 - val_loss: 10.0744 - val_mse: 10.0744 - val_mae: 1.9513\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3005 - mse: 8.3005 - mae: 1.6989 - val_loss: 10.0739 - val_mse: 10.0739 - val_mae: 1.9499\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3011 - mse: 8.3011 - mae: 1.7005 - val_loss: 10.0686 - val_mse: 10.0686 - val_mae: 1.9478\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3010 - mse: 8.3010 - mae: 1.6999 - val_loss: 10.0767 - val_mse: 10.0767 - val_mae: 1.9500\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 8.3030 - mse: 8.3030 - mae: 1.6994 - val_loss: 10.0600 - val_mse: 10.0600 - val_mae: 1.9506\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3020 - mse: 8.3020 - mae: 1.6987 - val_loss: 10.0492 - val_mse: 10.0492 - val_mae: 1.9508\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3019 - mse: 8.3019 - mae: 1.6987 - val_loss: 10.0403 - val_mse: 10.0403 - val_mae: 1.9500\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3005 - mse: 8.3005 - mae: 1.6986 - val_loss: 10.0444 - val_mse: 10.0444 - val_mae: 1.9486\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3005 - mse: 8.3005 - mae: 1.6989 - val_loss: 10.0453 - val_mse: 10.0453 - val_mae: 1.9476\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 8.3058 - mse: 8.3058 - mae: 1.7004 - val_loss: 10.0763 - val_mse: 10.0763 - val_mae: 1.9512\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.3017 - mse: 8.3017 - mae: 1.6996 - val_loss: 10.0636 - val_mse: 10.0636 - val_mae: 1.9490\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.3017 - mse: 8.3017 - mae: 1.6994 - val_loss: 10.0772 - val_mse: 10.0772 - val_mae: 1.9512\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3005 - mse: 8.3005 - mae: 1.6992 - val_loss: 10.0782 - val_mse: 10.0782 - val_mae: 1.9515\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3027 - mse: 8.3027 - mae: 1.6993 - val_loss: 10.0919 - val_mse: 10.0919 - val_mae: 1.9524\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3004 - mse: 8.3004 - mae: 1.6992 - val_loss: 10.0860 - val_mse: 10.0860 - val_mae: 1.9510\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3050 - mse: 8.3050 - mae: 1.6999 - val_loss: 10.1021 - val_mse: 10.1021 - val_mae: 1.9523\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3018 - mse: 8.3018 - mae: 1.6994 - val_loss: 10.1025 - val_mse: 10.1025 - val_mae: 1.9519\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.3012 - mse: 8.3012 - mae: 1.6996 - val_loss: 10.0781 - val_mse: 10.0781 - val_mae: 1.9495\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3003 - mse: 8.3003 - mae: 1.6996 - val_loss: 10.0668 - val_mse: 10.0668 - val_mae: 1.9496\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3005 - mse: 8.3005 - mae: 1.6991 - val_loss: 10.0507 - val_mse: 10.0507 - val_mae: 1.9491\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3003 - mse: 8.3003 - mae: 1.6988 - val_loss: 10.0402 - val_mse: 10.0402 - val_mae: 1.9490\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3022 - mse: 8.3022 - mae: 1.6992 - val_loss: 10.0506 - val_mse: 10.0506 - val_mae: 1.9508\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3007 - mse: 8.3007 - mae: 1.6989 - val_loss: 10.0508 - val_mse: 10.0508 - val_mae: 1.9502\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3042 - mse: 8.3042 - mae: 1.6990 - val_loss: 10.0214 - val_mse: 10.0214 - val_mae: 1.9463\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3003 - mse: 8.3003 - mae: 1.6989 - val_loss: 10.0221 - val_mse: 10.0221 - val_mae: 1.9459\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3009 - mse: 8.3009 - mae: 1.6991 - val_loss: 10.0318 - val_mse: 10.0318 - val_mae: 1.9466\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3026 - mse: 8.3026 - mae: 1.6999 - val_loss: 10.0496 - val_mse: 10.0496 - val_mae: 1.9495\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3002 - mse: 8.3002 - mae: 1.6989 - val_loss: 10.0475 - val_mse: 10.0475 - val_mae: 1.9491\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3015 - mse: 8.3015 - mae: 1.6993 - val_loss: 10.0340 - val_mse: 10.0340 - val_mae: 1.9472\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3002 - mse: 8.3002 - mae: 1.6990 - val_loss: 10.0351 - val_mse: 10.0351 - val_mae: 1.9480\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3057 - mse: 8.3057 - mae: 1.6996 - val_loss: 10.0648 - val_mse: 10.0648 - val_mae: 1.9507\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3032 - mse: 8.3032 - mae: 1.6995 - val_loss: 10.0437 - val_mse: 10.0437 - val_mae: 1.9483\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3069 - mse: 8.3069 - mae: 1.6995 - val_loss: 10.0752 - val_mse: 10.0752 - val_mae: 1.9515\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3002 - mse: 8.3002 - mae: 1.6990 - val_loss: 10.0723 - val_mse: 10.0723 - val_mae: 1.9514\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3007 - mse: 8.3007 - mae: 1.6994 - val_loss: 10.0595 - val_mse: 10.0595 - val_mae: 1.9490\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3032 - mse: 8.3032 - mae: 1.6997 - val_loss: 10.0379 - val_mse: 10.0379 - val_mae: 1.9468\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.3008 - mse: 8.3008 - mae: 1.6992 - val_loss: 10.0501 - val_mse: 10.0501 - val_mae: 1.9492\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 8.3018 - mse: 8.3018 - mae: 1.6991 - val_loss: 10.0369 - val_mse: 10.0369 - val_mae: 1.9482\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3020 - mse: 8.3020 - mae: 1.6995 - val_loss: 10.0567 - val_mse: 10.0567 - val_mae: 1.9514\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3001 - mse: 8.3001 - mae: 1.6988 - val_loss: 10.0587 - val_mse: 10.0587 - val_mae: 1.9505\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3015 - mse: 8.3015 - mae: 1.6991 - val_loss: 10.0722 - val_mse: 10.0722 - val_mae: 1.9504\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3007 - mse: 8.3007 - mae: 1.6992 - val_loss: 10.0786 - val_mse: 10.0786 - val_mae: 1.9505\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3024 - mse: 8.3024 - mae: 1.6995 - val_loss: 10.0909 - val_mse: 10.0909 - val_mae: 1.9511\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3038 - mse: 8.3038 - mae: 1.6995 - val_loss: 10.0612 - val_mse: 10.0612 - val_mae: 1.9488\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3011 - mse: 8.3011 - mae: 1.6995 - val_loss: 10.0702 - val_mse: 10.0702 - val_mae: 1.9503\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 8.3039 - mse: 8.3039 - mae: 1.6996 - val_loss: 10.0873 - val_mse: 10.0873 - val_mae: 1.9524\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3000 - mse: 8.3000 - mae: 1.6993 - val_loss: 10.0748 - val_mse: 10.0748 - val_mae: 1.9509\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3017 - mse: 8.3017 - mae: 1.6994 - val_loss: 10.0813 - val_mse: 10.0813 - val_mae: 1.9513\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3002 - mse: 8.3002 - mae: 1.6992 - val_loss: 10.0634 - val_mse: 10.0634 - val_mae: 1.9498\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3006 - mse: 8.3006 - mae: 1.6993 - val_loss: 10.0649 - val_mse: 10.0649 - val_mae: 1.9499\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3007 - mse: 8.3007 - mae: 1.7002 - val_loss: 10.0632 - val_mse: 10.0632 - val_mae: 1.9512\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3018 - mse: 8.3018 - mae: 1.6993 - val_loss: 10.0374 - val_mse: 10.0374 - val_mae: 1.9475\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3012 - mse: 8.3012 - mae: 1.6997 - val_loss: 10.0449 - val_mse: 10.0449 - val_mae: 1.9470\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 8.3008 - mse: 8.3008 - mae: 1.6996 - val_loss: 10.0515 - val_mse: 10.0515 - val_mae: 1.9484\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3026 - mse: 8.3026 - mae: 1.6996 - val_loss: 10.0288 - val_mse: 10.0288 - val_mae: 1.9481\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3004 - mse: 8.3004 - mae: 1.6988 - val_loss: 10.0212 - val_mse: 10.0212 - val_mae: 1.9479\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3040 - mse: 8.3040 - mae: 1.6988 - val_loss: 10.0462 - val_mse: 10.0462 - val_mae: 1.9500\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3030 - mse: 8.3030 - mae: 1.6996 - val_loss: 10.0646 - val_mse: 10.0646 - val_mae: 1.9509\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3009 - mse: 8.3009 - mae: 1.6992 - val_loss: 10.0713 - val_mse: 10.0713 - val_mae: 1.9500\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3000 - mse: 8.3000 - mae: 1.6996 - val_loss: 10.0590 - val_mse: 10.0590 - val_mae: 1.9475\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3017 - mse: 8.3017 - mae: 1.6999 - val_loss: 10.0401 - val_mse: 10.0401 - val_mae: 1.9463\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3020 - mse: 8.3020 - mae: 1.7003 - val_loss: 10.0575 - val_mse: 10.0575 - val_mae: 1.9503\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.3096 - mse: 8.3096 - mae: 1.7008 - val_loss: 10.0206 - val_mse: 10.0206 - val_mae: 1.9472\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3034 - mse: 8.3034 - mae: 1.6990 - val_loss: 10.0065 - val_mse: 10.0065 - val_mae: 1.9475\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3014 - mse: 8.3014 - mae: 1.6986 - val_loss: 10.0297 - val_mse: 10.0297 - val_mae: 1.9493\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3055 - mse: 8.3055 - mae: 1.6992 - val_loss: 10.0626 - val_mse: 10.0626 - val_mae: 1.9502\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3032 - mse: 8.3032 - mae: 1.6996 - val_loss: 10.0845 - val_mse: 10.0845 - val_mae: 1.9503\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3032 - mse: 8.3032 - mae: 1.7004 - val_loss: 10.0615 - val_mse: 10.0615 - val_mae: 1.9474\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3021 - mse: 8.3021 - mae: 1.7008 - val_loss: 10.0468 - val_mse: 10.0468 - val_mae: 1.9472\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3004 - mse: 8.3004 - mae: 1.6995 - val_loss: 10.0610 - val_mse: 10.0610 - val_mae: 1.9520\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.2997 - mse: 8.2997 - mae: 1.6990 - val_loss: 10.0650 - val_mse: 10.0650 - val_mae: 1.9528\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.2999 - mse: 8.2999 - mae: 1.6992 - val_loss: 10.0671 - val_mse: 10.0671 - val_mae: 1.9523\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3016 - mse: 8.3016 - mae: 1.6993 - val_loss: 10.0498 - val_mse: 10.0498 - val_mae: 1.9477\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3108 - mse: 8.3108 - mae: 1.7028 - val_loss: 10.0164 - val_mse: 10.0164 - val_mae: 1.9427\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3001 - mse: 8.3001 - mae: 1.7005 - val_loss: 10.0330 - val_mse: 10.0330 - val_mae: 1.9462\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3030 - mse: 8.3030 - mae: 1.7002 - val_loss: 10.0654 - val_mse: 10.0654 - val_mae: 1.9519\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 8.3013 - mse: 8.3013 - mae: 1.6992 - val_loss: 10.0563 - val_mse: 10.0563 - val_mae: 1.9517\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3024 - mse: 8.3024 - mae: 1.6993 - val_loss: 10.0440 - val_mse: 10.0440 - val_mae: 1.9494\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3012 - mse: 8.3012 - mae: 1.6993 - val_loss: 10.0383 - val_mse: 10.0383 - val_mae: 1.9479\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3009 - mse: 8.3009 - mae: 1.6992 - val_loss: 10.0630 - val_mse: 10.0630 - val_mae: 1.9497\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3006 - mse: 8.3006 - mae: 1.6994 - val_loss: 10.0583 - val_mse: 10.0583 - val_mae: 1.9490\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3008 - mse: 8.3008 - mae: 1.6995 - val_loss: 10.0801 - val_mse: 10.0801 - val_mae: 1.9512\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3007 - mse: 8.3007 - mae: 1.6998 - val_loss: 10.0968 - val_mse: 10.0968 - val_mae: 1.9526\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.3004 - mse: 8.3004 - mae: 1.6996 - val_loss: 10.1062 - val_mse: 10.1062 - val_mae: 1.9533\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3037 - mse: 8.3037 - mae: 1.7006 - val_loss: 10.0795 - val_mse: 10.0795 - val_mae: 1.9496\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3000 - mse: 8.3000 - mae: 1.6999 - val_loss: 10.0876 - val_mse: 10.0876 - val_mae: 1.9511\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 8.3012 - mse: 8.3012 - mae: 1.7000 - val_loss: 10.0707 - val_mse: 10.0707 - val_mae: 1.9499\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.2994 - mse: 8.2994 - mae: 1.6993 - val_loss: 10.0742 - val_mse: 10.0742 - val_mae: 1.9515\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3036 - mse: 8.3036 - mae: 1.7005 - val_loss: 10.0951 - val_mse: 10.0951 - val_mae: 1.9547\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2997 - mse: 8.2997 - mae: 1.6994 - val_loss: 10.0885 - val_mse: 10.0885 - val_mae: 1.9531\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3052 - mse: 8.3052 - mae: 1.7012 - val_loss: 10.0532 - val_mse: 10.0532 - val_mae: 1.9466\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3010 - mse: 8.3010 - mae: 1.7005 - val_loss: 10.0657 - val_mse: 10.0657 - val_mae: 1.9477\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3006 - mse: 8.3006 - mae: 1.7003 - val_loss: 10.0513 - val_mse: 10.0513 - val_mae: 1.9477\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3011 - mse: 8.3011 - mae: 1.7001 - val_loss: 10.0667 - val_mse: 10.0667 - val_mae: 1.9514\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.2993 - mse: 8.2993 - mae: 1.6992 - val_loss: 10.0646 - val_mse: 10.0646 - val_mae: 1.9517\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3084 - mse: 8.3084 - mae: 1.7004 - val_loss: 10.0945 - val_mse: 10.0945 - val_mae: 1.9540\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3071 - mse: 8.3071 - mae: 1.6999 - val_loss: 10.0523 - val_mse: 10.0523 - val_mae: 1.9478\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 8.2993 - mse: 8.2993 - mae: 1.6999 - val_loss: 10.0510 - val_mse: 10.0510 - val_mae: 1.9467\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.3084 - mse: 8.3084 - mae: 1.7019 - val_loss: 10.0826 - val_mse: 10.0826 - val_mae: 1.9514\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3045 - mse: 8.3045 - mae: 1.7000 - val_loss: 10.0494 - val_mse: 10.0494 - val_mae: 1.9480\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3068 - mse: 8.3068 - mae: 1.7003 - val_loss: 10.0183 - val_mse: 10.0183 - val_mae: 1.9458\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3002 - mse: 8.3002 - mae: 1.6990 - val_loss: 10.0352 - val_mse: 10.0352 - val_mae: 1.9486\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3010 - mse: 8.3010 - mae: 1.6993 - val_loss: 10.0545 - val_mse: 10.0545 - val_mae: 1.9514\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3065 - mse: 8.3065 - mae: 1.7002 - val_loss: 10.0258 - val_mse: 10.0258 - val_mae: 1.9480\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3006 - mse: 8.3006 - mae: 1.6991 - val_loss: 10.0451 - val_mse: 10.0451 - val_mae: 1.9494\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3182 - mse: 8.3182 - mae: 1.7044 - val_loss: 10.0030 - val_mse: 10.0030 - val_mae: 1.9426\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.2996 - mse: 8.2996 - mae: 1.7002 - val_loss: 10.0226 - val_mse: 10.0226 - val_mae: 1.9458\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.3057 - mse: 8.3057 - mae: 1.7001 - val_loss: 10.0099 - val_mse: 10.0099 - val_mae: 1.9465\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 8.2992 - mse: 8.2992 - mae: 1.6989 - val_loss: 10.0260 - val_mse: 10.0260 - val_mae: 1.9493\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.2991 - mse: 8.2991 - mae: 1.6990 - val_loss: 10.0422 - val_mse: 10.0422 - val_mae: 1.9504\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2991 - mse: 8.2991 - mae: 1.6991 - val_loss: 10.0543 - val_mse: 10.0543 - val_mae: 1.9504\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3032 - mse: 8.3032 - mae: 1.6996 - val_loss: 10.0906 - val_mse: 10.0906 - val_mae: 1.9526\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3038 - mse: 8.3038 - mae: 1.7019 - val_loss: 10.0755 - val_mse: 10.0755 - val_mae: 1.9480\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.3004 - mse: 8.3004 - mae: 1.7004 - val_loss: 10.0979 - val_mse: 10.0979 - val_mae: 1.9511\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.2996 - mse: 8.2996 - mae: 1.6998 - val_loss: 10.0961 - val_mse: 10.0961 - val_mae: 1.9526\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3009 - mse: 8.3009 - mae: 1.7000 - val_loss: 10.0858 - val_mse: 10.0858 - val_mae: 1.9518\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.2992 - mse: 8.2992 - mae: 1.6995 - val_loss: 10.0869 - val_mse: 10.0869 - val_mae: 1.9528\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3020 - mse: 8.3020 - mae: 1.7000 - val_loss: 10.1083 - val_mse: 10.1083 - val_mae: 1.9540\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3008 - mse: 8.3008 - mae: 1.6999 - val_loss: 10.0915 - val_mse: 10.0915 - val_mae: 1.9517\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3012 - mse: 8.3012 - mae: 1.7000 - val_loss: 10.0743 - val_mse: 10.0743 - val_mae: 1.9494\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 8.2999 - mse: 8.2999 - mae: 1.6996 - val_loss: 10.0660 - val_mse: 10.0660 - val_mae: 1.9495\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 8.2989 - mse: 8.2989 - mae: 1.6994 - val_loss: 10.0701 - val_mse: 10.0701 - val_mae: 1.9505\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3008 - mse: 8.3008 - mae: 1.6996 - val_loss: 10.0869 - val_mse: 10.0869 - val_mae: 1.9521\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2999 - mse: 8.2999 - mae: 1.6996 - val_loss: 10.0742 - val_mse: 10.0742 - val_mae: 1.9508\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 8.3111 - mse: 8.3111 - mae: 1.7010 - val_loss: 10.0363 - val_mse: 10.0363 - val_mae: 1.9477\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3016 - mse: 8.3016 - mae: 1.7000 - val_loss: 10.0609 - val_mse: 10.0609 - val_mae: 1.9506\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2991 - mse: 8.2991 - mae: 1.6995 - val_loss: 10.0630 - val_mse: 10.0630 - val_mae: 1.9492\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3024 - mse: 8.3024 - mae: 1.7003 - val_loss: 10.0860 - val_mse: 10.0860 - val_mae: 1.9518\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.2992 - mse: 8.2992 - mae: 1.6996 - val_loss: 10.0779 - val_mse: 10.0779 - val_mae: 1.9505\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.2999 - mse: 8.2999 - mae: 1.7001 - val_loss: 10.0867 - val_mse: 10.0867 - val_mae: 1.9518\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3002 - mse: 8.3002 - mae: 1.7001 - val_loss: 10.0943 - val_mse: 10.0943 - val_mae: 1.9509\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3026 - mse: 8.3026 - mae: 1.7006 - val_loss: 10.1088 - val_mse: 10.1088 - val_mae: 1.9526\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2994 - mse: 8.2994 - mae: 1.7000 - val_loss: 10.1051 - val_mse: 10.1051 - val_mae: 1.9521\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2988 - mse: 8.2988 - mae: 1.6998 - val_loss: 10.0927 - val_mse: 10.0927 - val_mae: 1.9516\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2996 - mse: 8.2996 - mae: 1.7003 - val_loss: 10.0883 - val_mse: 10.0883 - val_mae: 1.9527\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.2996 - mse: 8.2996 - mae: 1.6998 - val_loss: 10.0854 - val_mse: 10.0854 - val_mae: 1.9521\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3024 - mse: 8.3024 - mae: 1.7010 - val_loss: 10.0511 - val_mse: 10.0511 - val_mae: 1.9467\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.3004 - mse: 8.3004 - mae: 1.7005 - val_loss: 10.0581 - val_mse: 10.0581 - val_mae: 1.9483\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3000 - mse: 8.3000 - mae: 1.7000 - val_loss: 10.0390 - val_mse: 10.0390 - val_mae: 1.9473\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.2990 - mse: 8.2990 - mae: 1.6997 - val_loss: 10.0420 - val_mse: 10.0420 - val_mae: 1.9491\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2994 - mse: 8.2994 - mae: 1.6996 - val_loss: 10.0478 - val_mse: 10.0478 - val_mae: 1.9508\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3028 - mse: 8.3028 - mae: 1.6998 - val_loss: 10.0222 - val_mse: 10.0222 - val_mae: 1.9472\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.2989 - mse: 8.2989 - mae: 1.6992 - val_loss: 10.0279 - val_mse: 10.0279 - val_mae: 1.9472\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3000 - mse: 8.3000 - mae: 1.6997 - val_loss: 10.0426 - val_mse: 10.0426 - val_mae: 1.9485\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3001 - mse: 8.3001 - mae: 1.6996 - val_loss: 10.0573 - val_mse: 10.0573 - val_mae: 1.9490\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3080 - mse: 8.3080 - mae: 1.7007 - val_loss: 10.0901 - val_mse: 10.0901 - val_mae: 1.9518\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 8.2997 - mse: 8.2997 - mae: 1.6998 - val_loss: 10.0938 - val_mse: 10.0938 - val_mae: 1.9513\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 8.3005 - mse: 8.3005 - mae: 1.7005 - val_loss: 10.0699 - val_mse: 10.0699 - val_mae: 1.9483\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2987 - mse: 8.2987 - mae: 1.7004 - val_loss: 10.0649 - val_mse: 10.0649 - val_mae: 1.9486\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3004 - mse: 8.3004 - mae: 1.7000 - val_loss: 10.0473 - val_mse: 10.0473 - val_mae: 1.9488\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.2986 - mse: 8.2986 - mae: 1.6994 - val_loss: 10.0468 - val_mse: 10.0468 - val_mae: 1.9502\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2987 - mse: 8.2987 - mae: 1.6993 - val_loss: 10.0476 - val_mse: 10.0476 - val_mae: 1.9501\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.2987 - mse: 8.2987 - mae: 1.6992 - val_loss: 10.0460 - val_mse: 10.0460 - val_mae: 1.9495\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3009 - mse: 8.3009 - mae: 1.6996 - val_loss: 10.0634 - val_mse: 10.0634 - val_mae: 1.9494\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2987 - mse: 8.2987 - mae: 1.6997 - val_loss: 10.0658 - val_mse: 10.0658 - val_mae: 1.9491\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3006 - mse: 8.3006 - mae: 1.7001 - val_loss: 10.0491 - val_mse: 10.0491 - val_mae: 1.9469\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2994 - mse: 8.2994 - mae: 1.7001 - val_loss: 10.0429 - val_mse: 10.0429 - val_mae: 1.9478\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2987 - mse: 8.2987 - mae: 1.6994 - val_loss: 10.0505 - val_mse: 10.0505 - val_mae: 1.9503\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3071 - mse: 8.3071 - mae: 1.7019 - val_loss: 10.0862 - val_mse: 10.0862 - val_mae: 1.9546\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.2989 - mse: 8.2989 - mae: 1.6994 - val_loss: 10.0779 - val_mse: 10.0779 - val_mae: 1.9509\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.2999 - mse: 8.2999 - mae: 1.7002 - val_loss: 10.0622 - val_mse: 10.0622 - val_mae: 1.9471\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2996 - mse: 8.2996 - mae: 1.7008 - val_loss: 10.0525 - val_mse: 10.0525 - val_mae: 1.9465\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2987 - mse: 8.2987 - mae: 1.7007 - val_loss: 10.0553 - val_mse: 10.0553 - val_mae: 1.9493\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3046 - mse: 8.3046 - mae: 1.7001 - val_loss: 10.0321 - val_mse: 10.0321 - val_mae: 1.9483\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3053 - mse: 8.3053 - mae: 1.7010 - val_loss: 10.0697 - val_mse: 10.0697 - val_mae: 1.9530\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 8.3047 - mse: 8.3047 - mae: 1.6998 - val_loss: 10.0438 - val_mse: 10.0438 - val_mae: 1.9491\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2985 - mse: 8.2985 - mae: 1.6993 - val_loss: 10.0473 - val_mse: 10.0473 - val_mae: 1.9483\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3016 - mse: 8.3016 - mae: 1.7002 - val_loss: 10.0353 - val_mse: 10.0353 - val_mae: 1.9460\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 8.3029 - mse: 8.3029 - mae: 1.7009 - val_loss: 10.0697 - val_mse: 10.0697 - val_mae: 1.9503\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.2987 - mse: 8.2987 - mae: 1.6998 - val_loss: 10.0816 - val_mse: 10.0816 - val_mae: 1.9509\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2987 - mse: 8.2987 - mae: 1.7001 - val_loss: 10.0797 - val_mse: 10.0797 - val_mae: 1.9504\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3014 - mse: 8.3014 - mae: 1.7011 - val_loss: 10.0646 - val_mse: 10.0646 - val_mae: 1.9489\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 8.3088 - mse: 8.3088 - mae: 1.7012 - val_loss: 10.1068 - val_mse: 10.1068 - val_mae: 1.9542\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2998 - mse: 8.2998 - mae: 1.6997 - val_loss: 10.0914 - val_mse: 10.0914 - val_mae: 1.9531\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2999 - mse: 8.2999 - mae: 1.6999 - val_loss: 10.1023 - val_mse: 10.1023 - val_mae: 1.9535\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2984 - mse: 8.2984 - mae: 1.6998 - val_loss: 10.0953 - val_mse: 10.0953 - val_mae: 1.9517\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2987 - mse: 8.2987 - mae: 1.7000 - val_loss: 10.0960 - val_mse: 10.0960 - val_mae: 1.9509\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.2986 - mse: 8.2986 - mae: 1.7006 - val_loss: 10.0933 - val_mse: 10.0933 - val_mae: 1.9503\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2992 - mse: 8.2992 - mae: 1.7006 - val_loss: 10.0962 - val_mse: 10.0962 - val_mae: 1.9519\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2983 - mse: 8.2983 - mae: 1.7000 - val_loss: 10.0890 - val_mse: 10.0890 - val_mae: 1.9517\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2986 - mse: 8.2986 - mae: 1.6998 - val_loss: 10.0736 - val_mse: 10.0736 - val_mae: 1.9516\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3006 - mse: 8.3006 - mae: 1.7001 - val_loss: 10.0828 - val_mse: 10.0828 - val_mae: 1.9524\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 8.3012 - mse: 8.3012 - mae: 1.7000 - val_loss: 10.0907 - val_mse: 10.0907 - val_mae: 1.9525\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.3000 - mse: 8.3000 - mae: 1.7001 - val_loss: 10.0618 - val_mse: 10.0618 - val_mae: 1.9479\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.2987 - mse: 8.2987 - mae: 1.7003 - val_loss: 10.0466 - val_mse: 10.0466 - val_mae: 1.9464\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3010 - mse: 8.3010 - mae: 1.7006 - val_loss: 10.0606 - val_mse: 10.0606 - val_mae: 1.9487\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3006 - mse: 8.3006 - mae: 1.7001 - val_loss: 10.0379 - val_mse: 10.0379 - val_mae: 1.9476\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.2990 - mse: 8.2990 - mae: 1.6996 - val_loss: 10.0294 - val_mse: 10.0294 - val_mae: 1.9488\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.2985 - mse: 8.2985 - mae: 1.6994 - val_loss: 10.0342 - val_mse: 10.0342 - val_mae: 1.9497\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3062 - mse: 8.3062 - mae: 1.7001 - val_loss: 10.0054 - val_mse: 10.0054 - val_mae: 1.9459\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2988 - mse: 8.2988 - mae: 1.6997 - val_loss: 10.0136 - val_mse: 10.0136 - val_mae: 1.9449\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.2998 - mse: 8.2998 - mae: 1.7004 - val_loss: 10.0123 - val_mse: 10.0123 - val_mae: 1.9449\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.2985 - mse: 8.2985 - mae: 1.6994 - val_loss: 10.0329 - val_mse: 10.0329 - val_mae: 1.9486\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.3074 - mse: 8.3074 - mae: 1.7010 - val_loss: 10.0129 - val_mse: 10.0129 - val_mae: 1.9465\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3027 - mse: 8.3027 - mae: 1.7002 - val_loss: 10.0552 - val_mse: 10.0552 - val_mae: 1.9514\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2982 - mse: 8.2982 - mae: 1.6998 - val_loss: 10.0682 - val_mse: 10.0682 - val_mae: 1.9508\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 8.2980 - mse: 8.2980 - mae: 1.6997 - val_loss: 10.0784 - val_mse: 10.0784 - val_mae: 1.9508\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2982 - mse: 8.2982 - mae: 1.7000 - val_loss: 10.0819 - val_mse: 10.0819 - val_mae: 1.9499\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3072 - mse: 8.3072 - mae: 1.7010 - val_loss: 10.1220 - val_mse: 10.1220 - val_mae: 1.9533\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2994 - mse: 8.2994 - mae: 1.7008 - val_loss: 10.1304 - val_mse: 10.1304 - val_mae: 1.9550\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2995 - mse: 8.2995 - mae: 1.7017 - val_loss: 10.1159 - val_mse: 10.1159 - val_mae: 1.9516\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2994 - mse: 8.2994 - mae: 1.7014 - val_loss: 10.1197 - val_mse: 10.1197 - val_mae: 1.9541\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2983 - mse: 8.2983 - mae: 1.7003 - val_loss: 10.1115 - val_mse: 10.1115 - val_mae: 1.9540\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 8.3019 - mse: 8.3019 - mae: 1.7006 - val_loss: 10.0799 - val_mse: 10.0799 - val_mae: 1.9506\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2980 - mse: 8.2980 - mae: 1.6999 - val_loss: 10.0762 - val_mse: 10.0762 - val_mae: 1.9497\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3002 - mse: 8.3002 - mae: 1.7001 - val_loss: 10.0551 - val_mse: 10.0551 - val_mae: 1.9480\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.2987 - mse: 8.2987 - mae: 1.7000 - val_loss: 10.0640 - val_mse: 10.0640 - val_mae: 1.9492\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2984 - mse: 8.2984 - mae: 1.7000 - val_loss: 10.0692 - val_mse: 10.0692 - val_mae: 1.9501\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2992 - mse: 8.2992 - mae: 1.7002 - val_loss: 10.0546 - val_mse: 10.0546 - val_mae: 1.9494\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3009 - mse: 8.3009 - mae: 1.7006 - val_loss: 10.0738 - val_mse: 10.0738 - val_mae: 1.9525\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.2983 - mse: 8.2983 - mae: 1.6999 - val_loss: 10.0640 - val_mse: 10.0640 - val_mae: 1.9508\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.3000 - mse: 8.3000 - mae: 1.7007 - val_loss: 10.0467 - val_mse: 10.0467 - val_mae: 1.9468\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3014 - mse: 8.3014 - mae: 1.7004 - val_loss: 10.0692 - val_mse: 10.0692 - val_mae: 1.9494\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2981 - mse: 8.2981 - mae: 1.7005 - val_loss: 10.0659 - val_mse: 10.0659 - val_mae: 1.9488\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2982 - mse: 8.2982 - mae: 1.7001 - val_loss: 10.0702 - val_mse: 10.0702 - val_mae: 1.9511\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2994 - mse: 8.2994 - mae: 1.7000 - val_loss: 10.0822 - val_mse: 10.0822 - val_mae: 1.9525\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.3016 - mse: 8.3016 - mae: 1.6999 - val_loss: 10.0562 - val_mse: 10.0562 - val_mae: 1.9495\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2979 - mse: 8.2979 - mae: 1.6997 - val_loss: 10.0548 - val_mse: 10.0548 - val_mae: 1.9486\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2983 - mse: 8.2983 - mae: 1.7000 - val_loss: 10.0630 - val_mse: 10.0630 - val_mae: 1.9487\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2990 - mse: 8.2990 - mae: 1.7004 - val_loss: 10.0517 - val_mse: 10.0517 - val_mae: 1.9482\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2979 - mse: 8.2979 - mae: 1.6998 - val_loss: 10.0533 - val_mse: 10.0533 - val_mae: 1.9489\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 8.2978 - mse: 8.2978 - mae: 1.6997 - val_loss: 10.0564 - val_mse: 10.0564 - val_mae: 1.9497\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2983 - mse: 8.2983 - mae: 1.6997 - val_loss: 10.0535 - val_mse: 10.0535 - val_mae: 1.9501\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.3039 - mse: 8.3039 - mae: 1.7012 - val_loss: 10.0850 - val_mse: 10.0850 - val_mae: 1.9530\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2985 - mse: 8.2985 - mae: 1.6998 - val_loss: 10.0913 - val_mse: 10.0913 - val_mae: 1.9513\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.2991 - mse: 8.2991 - mae: 1.7010 - val_loss: 10.0971 - val_mse: 10.0971 - val_mae: 1.9491\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2990 - mse: 8.2990 - mae: 1.7014 - val_loss: 10.0813 - val_mse: 10.0813 - val_mae: 1.9482\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3059 - mse: 8.3059 - mae: 1.7022 - val_loss: 10.1108 - val_mse: 10.1108 - val_mae: 1.9539\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2996 - mse: 8.2996 - mae: 1.7005 - val_loss: 10.1154 - val_mse: 10.1154 - val_mae: 1.9557\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 8.2991 - mse: 8.2991 - mae: 1.7003 - val_loss: 10.1126 - val_mse: 10.1126 - val_mae: 1.9550\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.3034 - mse: 8.3034 - mae: 1.7008 - val_loss: 10.0697 - val_mse: 10.0697 - val_mae: 1.9487\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2984 - mse: 8.2984 - mae: 1.7007 - val_loss: 10.0696 - val_mse: 10.0696 - val_mae: 1.9475\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2980 - mse: 8.2980 - mae: 1.7010 - val_loss: 10.0673 - val_mse: 10.0673 - val_mae: 1.9483\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3002 - mse: 8.3002 - mae: 1.7009 - val_loss: 10.0434 - val_mse: 10.0434 - val_mae: 1.9473\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3006 - mse: 8.3006 - mae: 1.6998 - val_loss: 10.0240 - val_mse: 10.0240 - val_mae: 1.9480\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2979 - mse: 8.2979 - mae: 1.6994 - val_loss: 10.0277 - val_mse: 10.0277 - val_mae: 1.9492\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2989 - mse: 8.2989 - mae: 1.6994 - val_loss: 10.0430 - val_mse: 10.0430 - val_mae: 1.9508\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.2979 - mse: 8.2979 - mae: 1.6994 - val_loss: 10.0475 - val_mse: 10.0475 - val_mae: 1.9498\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3040 - mse: 8.3040 - mae: 1.7018 - val_loss: 10.0227 - val_mse: 10.0227 - val_mae: 1.9445\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.2987 - mse: 8.2987 - mae: 1.7004 - val_loss: 10.0425 - val_mse: 10.0425 - val_mae: 1.9466\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2980 - mse: 8.2980 - mae: 1.7002 - val_loss: 10.0450 - val_mse: 10.0450 - val_mae: 1.9479\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2995 - mse: 8.2995 - mae: 1.6999 - val_loss: 10.0699 - val_mse: 10.0699 - val_mae: 1.9512\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 8.3009 - mse: 8.3009 - mae: 1.7010 - val_loss: 10.0947 - val_mse: 10.0947 - val_mae: 1.9541\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2987 - mse: 8.2987 - mae: 1.7001 - val_loss: 10.1038 - val_mse: 10.1038 - val_mae: 1.9530\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2977 - mse: 8.2977 - mae: 1.7002 - val_loss: 10.1017 - val_mse: 10.1017 - val_mae: 1.9509\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 8.2983 - mse: 8.2983 - mae: 1.7016 - val_loss: 10.0998 - val_mse: 10.0998 - val_mae: 1.9492\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2980 - mse: 8.2980 - mae: 1.7011 - val_loss: 10.1004 - val_mse: 10.1004 - val_mae: 1.9514\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3110 - mse: 8.3110 - mae: 1.7012 - val_loss: 10.0540 - val_mse: 10.0540 - val_mae: 1.9492\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2982 - mse: 8.2982 - mae: 1.6999 - val_loss: 10.0486 - val_mse: 10.0486 - val_mae: 1.9507\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2994 - mse: 8.2994 - mae: 1.6999 - val_loss: 10.0666 - val_mse: 10.0666 - val_mae: 1.9525\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2978 - mse: 8.2978 - mae: 1.6998 - val_loss: 10.0669 - val_mse: 10.0669 - val_mae: 1.9501\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 8.3023 - mse: 8.3023 - mae: 1.7004 - val_loss: 10.0424 - val_mse: 10.0424 - val_mae: 1.9462\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2981 - mse: 8.2981 - mae: 1.7012 - val_loss: 10.0480 - val_mse: 10.0480 - val_mae: 1.9459\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 8.2979 - mse: 8.2979 - mae: 1.7008 - val_loss: 10.0502 - val_mse: 10.0502 - val_mae: 1.9479\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.2975 - mse: 8.2975 - mae: 1.6998 - val_loss: 10.0637 - val_mse: 10.0637 - val_mae: 1.9513\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 8.2981 - mse: 8.2981 - mae: 1.7003 - val_loss: 10.0771 - val_mse: 10.0771 - val_mae: 1.9551\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2989 - mse: 8.2989 - mae: 1.7000 - val_loss: 10.0901 - val_mse: 10.0901 - val_mae: 1.9544\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2983 - mse: 8.2983 - mae: 1.6997 - val_loss: 10.0960 - val_mse: 10.0960 - val_mae: 1.9511\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3005 - mse: 8.3005 - mae: 1.7008 - val_loss: 10.1115 - val_mse: 10.1115 - val_mae: 1.9507\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2977 - mse: 8.2977 - mae: 1.7013 - val_loss: 10.1012 - val_mse: 10.1012 - val_mae: 1.9491\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2997 - mse: 8.2997 - mae: 1.7017 - val_loss: 10.1095 - val_mse: 10.1095 - val_mae: 1.9501\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3071 - mse: 8.3071 - mae: 1.7028 - val_loss: 10.1356 - val_mse: 10.1356 - val_mae: 1.9558\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2988 - mse: 8.2988 - mae: 1.7006 - val_loss: 10.1311 - val_mse: 10.1311 - val_mae: 1.9564\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 8.3001 - mse: 8.3001 - mae: 1.7001 - val_loss: 10.0931 - val_mse: 10.0931 - val_mae: 1.9527\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2976 - mse: 8.2976 - mae: 1.7000 - val_loss: 10.0706 - val_mse: 10.0706 - val_mae: 1.9497\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2973 - mse: 8.2973 - mae: 1.7002 - val_loss: 10.0599 - val_mse: 10.0599 - val_mae: 1.9475\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 8.2976 - mse: 8.2976 - mae: 1.7007 - val_loss: 10.0571 - val_mse: 10.0571 - val_mae: 1.9481\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.3000 - mse: 8.3000 - mae: 1.7011 - val_loss: 10.0320 - val_mse: 10.0320 - val_mae: 1.9463\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2989 - mse: 8.2989 - mae: 1.7000 - val_loss: 10.0201 - val_mse: 10.0201 - val_mae: 1.9478\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 8.2978 - mse: 8.2978 - mae: 1.6996 - val_loss: 10.0284 - val_mse: 10.0284 - val_mae: 1.9486\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.3000 - mse: 8.3000 - mae: 1.7007 - val_loss: 10.0151 - val_mse: 10.0151 - val_mae: 1.9461\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 8.3004 - mse: 8.3004 - mae: 1.7001 - val_loss: 10.0050 - val_mse: 10.0050 - val_mae: 1.9453\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2994 - mse: 8.2994 - mae: 1.6997 - val_loss: 10.0041 - val_mse: 10.0041 - val_mae: 1.9457\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2979 - mse: 8.2979 - mae: 1.7000 - val_loss: 10.0256 - val_mse: 10.0256 - val_mae: 1.9486\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.3012 - mse: 8.3012 - mae: 1.7007 - val_loss: 10.0191 - val_mse: 10.0191 - val_mae: 1.9462\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 8.2990 - mse: 8.2990 - mae: 1.7000 - val_loss: 10.0523 - val_mse: 10.0523 - val_mae: 1.9482\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2984 - mse: 8.2984 - mae: 1.7010 - val_loss: 10.0556 - val_mse: 10.0556 - val_mae: 1.9479\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.2971 - mse: 8.2971 - mae: 1.7003 - val_loss: 10.0719 - val_mse: 10.0719 - val_mae: 1.9501\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 8.2995 - mse: 8.2995 - mae: 1.7003 - val_loss: 10.1035 - val_mse: 10.1035 - val_mae: 1.9544\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 8.2974 - mse: 8.2974 - mae: 1.7002 - val_loss: 10.1125 - val_mse: 10.1125 - val_mae: 1.9546\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2990 - mse: 8.2990 - mae: 1.7004 - val_loss: 10.1009 - val_mse: 10.1009 - val_mae: 1.9525\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3005 - mse: 8.3005 - mae: 1.7009 - val_loss: 10.0840 - val_mse: 10.0840 - val_mae: 1.9495\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 8.2973 - mse: 8.2973 - mae: 1.7007 - val_loss: 10.0942 - val_mse: 10.0942 - val_mae: 1.9507\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2994 - mse: 8.2994 - mae: 1.7008 - val_loss: 10.0820 - val_mse: 10.0820 - val_mae: 1.9500\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2983 - mse: 8.2983 - mae: 1.7003 - val_loss: 10.1002 - val_mse: 10.1002 - val_mae: 1.9530\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2987 - mse: 8.2987 - mae: 1.7005 - val_loss: 10.1154 - val_mse: 10.1154 - val_mae: 1.9542\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2980 - mse: 8.2980 - mae: 1.7003 - val_loss: 10.1029 - val_mse: 10.1029 - val_mae: 1.9524\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2986 - mse: 8.2986 - mae: 1.7005 - val_loss: 10.0874 - val_mse: 10.0874 - val_mae: 1.9509\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.2971 - mse: 8.2971 - mae: 1.7003 - val_loss: 10.0854 - val_mse: 10.0854 - val_mae: 1.9504\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 8.2973 - mse: 8.2973 - mae: 1.7005 - val_loss: 10.0827 - val_mse: 10.0827 - val_mae: 1.9509\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 8.2972 - mse: 8.2972 - mae: 1.7007 - val_loss: 10.0807 - val_mse: 10.0807 - val_mae: 1.9500\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 8.2974 - mse: 8.2974 - mae: 1.7004 - val_loss: 10.0741 - val_mse: 10.0741 - val_mae: 1.9498\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 8.2975 - mse: 8.2975 - mae: 1.7001 - val_loss: 10.0681 - val_mse: 10.0681 - val_mae: 1.9501\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2991 - mse: 8.2991 - mae: 1.7003 - val_loss: 10.0864 - val_mse: 10.0864 - val_mae: 1.9521\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.2973 - mse: 8.2973 - mae: 1.7001 - val_loss: 10.0800 - val_mse: 10.0800 - val_mae: 1.9518\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2972 - mse: 8.2972 - mae: 1.7001 - val_loss: 10.0745 - val_mse: 10.0745 - val_mae: 1.9506\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.3131 - mse: 8.3131 - mae: 1.7042 - val_loss: 10.1180 - val_mse: 10.1180 - val_mae: 1.9544\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2978 - mse: 8.2978 - mae: 1.7004 - val_loss: 10.0978 - val_mse: 10.0978 - val_mae: 1.9500\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.3066 - mse: 8.3066 - mae: 1.7031 - val_loss: 10.1236 - val_mse: 10.1236 - val_mae: 1.9528\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.3055 - mse: 8.3055 - mae: 1.7043 - val_loss: 10.0777 - val_mse: 10.0777 - val_mae: 1.9469\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.2978 - mse: 8.2978 - mae: 1.7016 - val_loss: 10.0802 - val_mse: 10.0802 - val_mae: 1.9499\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.3031 - mse: 8.3031 - mae: 1.7012 - val_loss: 10.1014 - val_mse: 10.1014 - val_mae: 1.9545\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2972 - mse: 8.2972 - mae: 1.7000 - val_loss: 10.0863 - val_mse: 10.0863 - val_mae: 1.9534\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.2974 - mse: 8.2974 - mae: 1.7003 - val_loss: 10.0680 - val_mse: 10.0680 - val_mae: 1.9497\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2972 - mse: 8.2972 - mae: 1.7007 - val_loss: 10.0623 - val_mse: 10.0623 - val_mae: 1.9476\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.3036 - mse: 8.3036 - mae: 1.7020 - val_loss: 10.0281 - val_mse: 10.0281 - val_mae: 1.9448\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3016 - mse: 8.3016 - mae: 1.7007 - val_loss: 10.0542 - val_mse: 10.0542 - val_mae: 1.9495\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3038 - mse: 8.3038 - mae: 1.7013 - val_loss: 10.0819 - val_mse: 10.0819 - val_mae: 1.9538\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.2975 - mse: 8.2975 - mae: 1.7001 - val_loss: 10.0662 - val_mse: 10.0662 - val_mae: 1.9512\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3001 - mse: 8.3001 - mae: 1.7004 - val_loss: 10.0803 - val_mse: 10.0803 - val_mae: 1.9504\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2987 - mse: 8.2987 - mae: 1.7014 - val_loss: 10.0585 - val_mse: 10.0585 - val_mae: 1.9462\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 8.2998 - mse: 8.2998 - mae: 1.7013 - val_loss: 10.0382 - val_mse: 10.0382 - val_mae: 1.9457\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2971 - mse: 8.2971 - mae: 1.7004 - val_loss: 10.0406 - val_mse: 10.0406 - val_mae: 1.9478\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 8.3123 - mse: 8.3123 - mae: 1.7018 - val_loss: 10.0028 - val_mse: 10.0028 - val_mae: 1.9454\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2986 - mse: 8.2986 - mae: 1.7005 - val_loss: 10.0292 - val_mse: 10.0292 - val_mae: 1.9503\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2977 - mse: 8.2977 - mae: 1.6999 - val_loss: 10.0455 - val_mse: 10.0455 - val_mae: 1.9520\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 8.3126 - mse: 8.3126 - mae: 1.7012 - val_loss: 10.0962 - val_mse: 10.0962 - val_mae: 1.9532\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2969 - mse: 8.2969 - mae: 1.7006 - val_loss: 10.0935 - val_mse: 10.0935 - val_mae: 1.9487\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2971 - mse: 8.2971 - mae: 1.7017 - val_loss: 10.0911 - val_mse: 10.0911 - val_mae: 1.9471\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.2976 - mse: 8.2976 - mae: 1.7022 - val_loss: 10.0981 - val_mse: 10.0981 - val_mae: 1.9494\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2991 - mse: 8.2991 - mae: 1.7015 - val_loss: 10.1129 - val_mse: 10.1129 - val_mae: 1.9542\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2969 - mse: 8.2969 - mae: 1.7004 - val_loss: 10.1078 - val_mse: 10.1078 - val_mae: 1.9546\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2971 - mse: 8.2971 - mae: 1.7004 - val_loss: 10.0954 - val_mse: 10.0954 - val_mae: 1.9531\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2973 - mse: 8.2973 - mae: 1.7004 - val_loss: 10.0803 - val_mse: 10.0803 - val_mae: 1.9510\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.3035 - mse: 8.3035 - mae: 1.7017 - val_loss: 10.0467 - val_mse: 10.0467 - val_mae: 1.9466\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2980 - mse: 8.2980 - mae: 1.7009 - val_loss: 10.0382 - val_mse: 10.0382 - val_mae: 1.9461\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.3020 - mse: 8.3020 - mae: 1.7013 - val_loss: 10.0695 - val_mse: 10.0695 - val_mae: 1.9503\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2971 - mse: 8.2971 - mae: 1.7004 - val_loss: 10.0767 - val_mse: 10.0767 - val_mae: 1.9518\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2980 - mse: 8.2980 - mae: 1.7006 - val_loss: 10.0636 - val_mse: 10.0636 - val_mae: 1.9498\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.3000 - mse: 8.3000 - mae: 1.7007 - val_loss: 10.0855 - val_mse: 10.0855 - val_mae: 1.9518\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2979 - mse: 8.2979 - mae: 1.7009 - val_loss: 10.0705 - val_mse: 10.0705 - val_mae: 1.9491\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.2978 - mse: 8.2978 - mae: 1.7006 - val_loss: 10.0826 - val_mse: 10.0826 - val_mae: 1.9499\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 8.2990 - mse: 8.2990 - mae: 1.7016 - val_loss: 10.0657 - val_mse: 10.0657 - val_mae: 1.9475\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2971 - mse: 8.2971 - mae: 1.7010 - val_loss: 10.0623 - val_mse: 10.0623 - val_mae: 1.9489\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2982 - mse: 8.2982 - mae: 1.7005 - val_loss: 10.0804 - val_mse: 10.0804 - val_mae: 1.9524\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2996 - mse: 8.2996 - mae: 1.7003 - val_loss: 10.0992 - val_mse: 10.0992 - val_mae: 1.9540\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.3011 - mse: 8.3011 - mae: 1.7008 - val_loss: 10.0711 - val_mse: 10.0711 - val_mae: 1.9504\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 8.2982 - mse: 8.2982 - mae: 1.7003 - val_loss: 10.0841 - val_mse: 10.0841 - val_mae: 1.9499\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2968 - mse: 8.2968 - mae: 1.7008 - val_loss: 10.0777 - val_mse: 10.0777 - val_mae: 1.9491\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.2970 - mse: 8.2970 - mae: 1.7015 - val_loss: 10.0731 - val_mse: 10.0731 - val_mae: 1.9486\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 8.2981 - mse: 8.2981 - mae: 1.7010 - val_loss: 10.0875 - val_mse: 10.0875 - val_mae: 1.9523\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 8.2971 - mse: 8.2971 - mae: 1.7009 - val_loss: 10.0890 - val_mse: 10.0890 - val_mae: 1.9539\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.2990 - mse: 8.2990 - mae: 1.7006 - val_loss: 10.1008 - val_mse: 10.1008 - val_mae: 1.9538\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2973 - mse: 8.2973 - mae: 1.7006 - val_loss: 10.1008 - val_mse: 10.1008 - val_mae: 1.9509\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2986 - mse: 8.2986 - mae: 1.7015 - val_loss: 10.0758 - val_mse: 10.0758 - val_mae: 1.9473\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 8.2969 - mse: 8.2969 - mae: 1.7018 - val_loss: 10.0735 - val_mse: 10.0735 - val_mae: 1.9474\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.2967 - mse: 8.2967 - mae: 1.7012 - val_loss: 10.0718 - val_mse: 10.0718 - val_mae: 1.9500\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2987 - mse: 8.2987 - mae: 1.7006 - val_loss: 10.0541 - val_mse: 10.0541 - val_mae: 1.9506\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2968 - mse: 8.2968 - mae: 1.7001 - val_loss: 10.0590 - val_mse: 10.0590 - val_mae: 1.9513\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2969 - mse: 8.2969 - mae: 1.7001 - val_loss: 10.0557 - val_mse: 10.0557 - val_mae: 1.9507\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.2966 - mse: 8.2966 - mae: 1.7001 - val_loss: 10.0598 - val_mse: 10.0598 - val_mae: 1.9489\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2965 - mse: 8.2965 - mae: 1.7003 - val_loss: 10.0630 - val_mse: 10.0630 - val_mae: 1.9478\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.2968 - mse: 8.2968 - mae: 1.7008 - val_loss: 10.0590 - val_mse: 10.0590 - val_mae: 1.9470\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.2979 - mse: 8.2979 - mae: 1.7011 - val_loss: 10.0510 - val_mse: 10.0510 - val_mae: 1.9473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_model.evaluate(x_test, y_test, batch_size=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5QHjKBkWdb5",
        "outputId": "9825e405-0a34-401e-da67-2383dd9a5a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 3ms/step - loss: 5.9364 - mse: 5.9364 - mae: 1.5311\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.936374187469482, 5.936374187469482, 1.531141996383667]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res_keras = tf_model.predict(np.array([[50,32]]))\n",
        "res_keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBemUGmSXMHC",
        "outputId": "3760c4f5-065f-4d00-b86a-ac1d42b15e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[79.41146 ,  8.835081]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras_file = \"se_final.h5\"\n",
        "tf.keras.models.save_model(tf_model,keras_file)\n",
        "converter = lite.TFLiteConverter.from_keras_model(tf_model)\n",
        "keras_model = converter.convert()\n",
        "\n",
        "open(\"se_final.tflite\",\"wb\").write(keras_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ved6HjvYJmM",
        "outputId": "ad11baa9-cc51-4eb1-e4e2-5aafd1248d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpzimzfjgn/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "904"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SE13OVBaX55A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}